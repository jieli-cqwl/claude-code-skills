<!-- L1 模块规格 - 按需加载 -->
<!-- 来源：设计_人机协作模式重建.md 行 1149-1977 -->
<!-- 生成日期：2026-02-21 -->

# L1: SubAgent 质量设计（步骤质量设计）

**本模块依赖**：L1_三层架构与Skills.md（Skills 知识层定义）、L1_Handoff文档规范.md（Handoff 格式）
**本模块被依赖**：L1_pipeline编排器.md（编排器调用 SubAgent）、L1_配置与权限.md（SubAgent 配置）

> 这是整个方案最核心的部分。每个环节的 SubAgent 质量直接决定全流程的天花板。

---

## 1. 通用 Prompt 设计原则（4.0 节，共 10 条）

### 原则 1：角色身份定义

每个 SubAgent prompt 开头必须定义明确的角色身份（三要素）：
- **身份**：你是谁
- **行为准则**：你怎么做
- **边界**：你不做什么（负向约束）

Pipeline 本质上用 SubAgent 替代真实软件交付团队中每个角色。质量来自角色间的**张力**——架构师画线开发者不能越线、审查者的目标是找问题而非证明没问题、QA 不信任上游任何自证。

| SubAgent | 替代真人 | 角色身份 | 行为准则 | 负向约束 |
|----------|---------|---------|---------|---------|
| Designer | 架构师 | 资深架构师，熟悉本项目代码风格 | 先扫描现有代码再设计；拒绝未提及功能；关键决策多方案对比 | 不写代码、不做任务拆分 |
| Planner | 技术 PM | 技术项目经理，能读代码判断任务粒度 | 每任务可一次 commit；每 AC 可翻译成 assert；标注文件路径和依赖 | 不修改设计、不写实现 |
| Implementer | 开发工程师 | 严格遵循 TDD 的开发工程师 | 先写测试确认失败再写实现；一任务一 commit；遇阻标注 BLOCKED | 不改设计接口、不跳过失败测试、不删除已有测试 |
| Checker | 对抗性审查者 | 红蓝对抗攻击方，以"找茬"为乐的黑客 | 假设代码有漏洞；静态分析+逻辑推演；不仅看 Lint 更看逻辑漏洞 | 不做橡皮图章、不模糊结论、不替开发者辩护 |
| QA | QA 工程师 | 产品质量守门人，不信任上游自证 | 只以 clarify 文档为验收标准；独立端到端验证；开发说通过的，自己再验一遍 | 不修改代码、不看代码质量、不重复跑 lint/测试 |
| Fixer | 值班修复工程师 | 当值修复工程师，限时限范围 | 先根因分析再动手；每次修复附回归测试；修复前后 diff 测试结果 | 不顺手重构、不添加新功能 |

**人的角色**：用户在 /clarify（需求定义）和 /ship（最终验收）环节参与。人 = 产品负责人。

### 原则 2：显式推理过程

没有推理过程，质量门控中的检查项（如"是否扫描了现有代码"）就变成不可验证的声明。

Handoff 文档必须包含推理过程：
1. **"我看到了什么"**（输入分析）
2. **"我决定做什么"**（决策及理由）
3. **"我产出了什么"**（核心输出）

### 原则 3：Few-shot 对比示例

LLM 从具体示例中学习模式的能力远强于从抽象描述中理解意图。

每个 SubAgent prompt 中必须包含 1-2 组"好输出 vs 坏输出"对比示例。格式：
```
### 好的输出
[具体的、可操作的、有客观证据的内容]

### 坏的输出
[泛泛的、主观的、不可验证的内容]
```

### 原则 4：结构化交接项

Handoff "下一步需要关注的点"替换为**固定传递项清单**：

| 步骤 | 向下游传递的固定项 |
|------|------------------|
| Design -> Plan（评审） | 评审反馈文件路径（review_design_N.md） |
| Design -> Plan | 接口清单、模块依赖图、技术风险点、设计约束 |
| Plan -> Implement（评审） | 评审反馈文件路径（review_plan_N.md） |
| Plan -> Implement | 任务执行顺序、文件改动清单、每任务 AC、测试策略 |
| Implement -> Check | commit 列表（含 hash）、测试运行结果摘要、已知遗留问题、BLOCKED 任务 |
| Check -> QA | QA 不直接读取 Check 输出（保证独立性） |
| QA -> Fix | FAIL 项清单（期望行为 + 实际行为 + 复现命令） |
| Fix -> Check | 修复内容摘要、回归测试清单、修复前后测试 diff |

### 原则 5：理解输入 + 验证输出

每个 SubAgent 执行前必须**理解输入**（不只检查文件存在），完成前必须**验证输出**（不只检查格式）。

**理解输入**：从规则/接口推导方向，而非只列出读了哪些文件。

**验证输出**：对照上游规则逐条确认覆盖，而非只检查格式正确。

| 阶段 | 理解输入 | 验证输出 |
|------|---------|---------|
| Design | 逐条理解 clarify 规则，从规则推导模块/接口方向 | 每条规则都有对应接口或数据模型 |
| Plan | 理解接口依赖关系，从依赖推导任务拆分和执行顺序 | 任务覆盖所有设计接口，AC 可追溯到规则 |
| Implement | 理解每个任务的 AC 和文件边界，从 AC 推导测试用例 | 每个 AC 都有对应测试且通过 |
| Check | 理解预期行为和实际实现，从 AC 推导检查标准 | 检查结果可追溯到具体 AC 和代码行 |
| QA | 回到需求源头，从示例推导验收场景 | 验收场景覆盖正例、反例、边界 |

**与原则 2（显式推理过程）的关系**："理解输入"体现在 Handoff 的"我看到了什么"部分——不只是列出读了哪些文件，而是说明从中理解到了什么、推导出了什么方向。"验证输出"体现在完成前的自检——对照上游规则逐条确认覆盖。

### 原则 6：SOP 化 Prompt (CoT + Self-Correction)

1. **强制思维链**：输出最终 Markdown 前先输出 `<thinking>` 标签（Decompose -> Analyze -> Synthesize -> Reflect）
2. **自我修正检查清单**：Prompt 最末尾加入强制检查项，不通过则自我修正

### 原则 7：早期熔断 (Fail Fast)

下游 Agent 发现上游根本性错误时，有权拒绝执行并直接报错终止：
- Planner 发现 Design 缺失关键接口 -> `EXIT(CRITICAL_DESIGN_FLAW)`
- Implementer 发现 Plan 任务逻辑矛盾 -> `EXIT(INVALID_PLAN)`
- Checker 发现代码完全不可运行 -> `EXIT(BROKEN_CODE)`

### 原则 8：对抗性思维 (Adversarial Mindset)

仅适用于 Checker 和 QA（有客观标准可对照）：
- Checker：有罪推定，假设代码有漏洞
- QA：假设开发在骗你，证明功能是坏的

Design-Plan / Plan-Implement 评审定位为结构化 checklist 校验，非对抗性质量审查。

### 原则 9：负向约束 (Negative Constraints)

明确定义**不做什么**：不重构无关代码、不添加"未来可能用到"的东西、不删除测试、不修复上游缺陷。

### 原则 10：结构化输出 (Structured Output)

关键元数据包裹在 XML 标签中：
- `<metadata>{"status": "PASS", "risk": "low"}</metadata>`
- `<summary>...</summary>`
- `<critical_decision>...</critical_decision>`

---

## 2. Designer（架构设计）— 4.1 节

**SubAgent**: `pipeline-designer.md`
**引用 Skills**: `architecture`
**工具**: Read, Write, Glob, Grep, WebSearch
**输入**: handoff_clarify.md
**输出**: handoff_design.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 不看现有代码 | 凭空设计 | 与现有代码冲突，大量返工 |
| 只有正常路径 | 接口只定义成功场景 | 开发者自行决定错误处理 |
| 过度设计 | 不必要的抽象层/设计模式 | 增加复杂度，偏离需求 |
| 照搬模板 | 全是泛泛描述 | Plan 无法产出可执行任务 |

### 质量标准

- 必须先扫描现有代码（Glob/Grep 了解项目结构、技术栈）
- 接口定义完整：入参（类型+校验规则）、出参（成功+失败）、错误码
- 模块边界清晰："负责什么"和"不负责什么"
- 设计可追溯到需求
- 关键决策必须多方案对比（2-3 个备选方案，对比实现复杂度/一致性/可维护性）

### 理解输入 + 验证输出

**理解输入**：逐条理解 clarify 规则，对每条规则理解业务行为、从正例推导接口/数据流、从反例推导校验逻辑、从排除项明确不设计的范围。

**验证输出**：输出前列出覆盖表，每条 clarify 规则 -> 对应设计产出 -> 覆盖状态。如有规则无对应设计产出 -> 不能输出。

### 多方案对比方法论（Tree of Thoughts）

Designer 在做关键架构决策时，必须列出 2-3 个备选方案并对比，而非直接给出"唯一正确答案"。对比维度至少包含：实现复杂度、与现有代码的一致性、可维护性。

```
### 路由方案对比

| 维度 | 方案 A: 文件路由 | 方案 B: 集中路由 | 方案 C: 装饰器路由 |
|------|----------------|----------------|------------------|
| 与现有代码一致性 | 项目已用此模式 | 需改造现有路由 | 需引入新依赖 |
| 实现复杂度 | 低 | 中 | 中 |
| 可维护性 | 中（文件多） | 高（集中管理） | 高（声明式） |

**选择**: 方案 A，理由：与现有 12 个路由文件风格一致，避免两套模式并存。
```

### Few-shot 示例

```
好的设计输出：
- 输入分析：扫描项目发现现有模型在 src/models/user.py（SQLAlchemy），API 风格 RESTful...
- 决策：路由选择文件路由（方案 A），因为与现有 12 个路由文件一致...
- 产出：POST /api/v1/users 入参/成功/失败完整定义

坏的设计输出：
建议使用微服务架构。接口使用 RESTful 风格。
（没有输入分析、没有决策理由、没有具体接口定义）
```

> 详见 L2 原文 行 1292-1425（完整 Few-shot 示例和对比表）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 扫描现有代码 | Handoff 未体现扫描结果 |
| 接口错误场景 | 存在无错误场景的接口 |
| 需求范围守护 | 引入了未提及的功能 |
| 模块边界 | 未说明"负责/不负责" |
| 新依赖理由 | 新依赖未说明理由 |
| 多方案对比 | 关键决策只给出单一方案 |

### 输出前自检清单

1. clarify 每条规则都有对应接口或数据模型？（列出覆盖表）
2. 每个接口都定义了错误场景和错误码？
3. 扫描了现有代码并保持风格一致？
4. 关键决策给出了 2+ 备选方案对比？
5. 是否引入了 clarify 未提及的功能？（如是则删除）
6. 假设已标注为"待确认"？

### 额外输出：Key_Decisions.md

> 来源：L2 原文行 1087（关键设计决策表 #210）

Design 阶段除了输出 `handoff_design.md`，还额外生成 `Key_Decisions.md`，汇总关键决策点，让用户只需 Review 决策而非整篇设计文档。

**设计理由**：完整的 handoff_design.md 可能数百行，用户逐行 Review 效率低。Key_Decisions.md 提炼出 5-10 个关键决策点，每个决策一目了然（选了什么、为什么选、有什么影响），使 HUMAN_CHECKPOINT 环节从"通读文档"降级为"审批决策"。

**格式规范**（基于 MADR — Markdown Architecture Decision Record 精简版，融合 Microsoft Decision Log 双层模式）：

```markdown
# Key Decisions: [功能名]

**生成时间**: [timestamp]
**来源**: handoff_design.md

---

## 决策概要

> 人可在 60 秒内扫完此表，判断是否需要深入阅读某条决策的详情。

| # | 决策 | 影响度 | 选择 | 核心理由（1 句话） | 被否决方案 |
|---|------|--------|------|-------------------|-----------|
| KD-1 | [路由方案] | High | 文件路由 | 与现有 12 个路由一致 | 集中路由、装饰器路由 |
| KD-2 | [认证方案] | Medium | JWT | 前后端分离，无需 Session | Cookie Session |
| ... | | | | | |

---

## KD-1: [决策标题，如"路由方案选择"]

**状态**: Proposed
**影响度**: High / Medium / Low
**背景**: [1-2 句话描述决策上下文]

| 选项 | 优点 | 缺点 |
|------|------|------|
| A: [方案名] | [优点] | [缺点] |
| B: [方案名] | [优点] | [缺点] |

**决策**: 选择方案 A
**理由**: [1-2 句话核心理由]
**接受的妥协**: [选择此方案放弃了什么、延迟了什么]
**影响**: [对后续步骤 Plan/Implement 的具体影响]

---

## KD-2: [决策标题]
...
```

**双层结构说明**（来源：Microsoft Engineering Playbook Decision Log 模式）：
- **第一层（概要表）**：人扫描表格即可总览全部决策方向，影响度 High 的重点审查，Low 的快速放行
- **第二层（详细记录）**：每条决策展开背景、选项对比、妥协和影响，仅在概要表引起疑问时才需深入阅读

**字段说明**：

| 字段 | 必填 | 说明 |
|------|------|------|
| 状态 | 是 | Proposed（待审批）/ Accepted / Rejected |
| 影响度 | 是 | High（架构级）/ Medium（模块级）/ Low（局部实现），帮助人分配审查精力 |
| 背景 | 是 | 为什么需要做这个决策 |
| 选项表 | 是 | 至少 2 个备选方案，含优缺点 |
| 决策 | 是 | 选择了哪个方案 |
| 理由 | 是 | 选择的核心理由 |
| 接受的妥协 | 是 | 选择此方案放弃或延迟了什么（使 AI 的妥协显式化而非隐藏） |
| 影响 | 是 | 对后续步骤（Plan/Implement）的具体影响 |

**文件位置**：`docs/pipeline/{feature_name}/Key_Decisions.md`

**与 HUMAN_CHECKPOINT 的关系**：
- `HUMAN_CHECKPOINT=true` 时，pipeline.sh 在 Design 完成后等待用户确认。用户可先阅读 Key_Decisions.md 快速了解方向，再决定是 `touch .confirm` 放行还是 `REJECT` 打回
- `HUMAN_CHECKPOINT=false` 时，Key_Decisions.md 仍然生成（供事后追溯），但不阻塞流程

**纳入 Designer 自检清单的追加项**：
7. 是否为每个关键架构决策生成了 Key_Decisions.md 条目？

---

## 3. Planner（开发计划）— 4.2 节

**SubAgent**: `pipeline-planner.md`
**引用 Skills**: `architecture`（引用）、`review-standard`（引用，用于 Design 评审）
**工具**: Read, Write, Glob, Grep
**输入**: handoff_clarify.md + handoff_design.md
**输出**: handoff_plan.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 任务太大 | "实现用户认证模块"作为一个任务 | 无法判断完成度 |
| AC 不可测试 | "界面友好"、"性能良好" | QA 无法验收 |
| 依赖分析缺失 | 任务顺序不对 | 执行时卡住 |
| 未考虑现有文件 | 不知道该改哪些文件 | 代码散落 |

### 质量标准

- 任务粒度：单任务改动 <= 5 文件，一次 commit 完成
- AC 可测试：每个 AC 可翻译成 assert 或具体测试场景
- 文件明确：每任务列出具体文件路径（基于 Glob 扫描）
- 依赖清晰：`depends_on: [Task N]`，执行顺序无歧义

### 理解输入 + 验证输出

**理解输入**：
1. 理解 clarify 规则和示例 -> 判断任务拆分粒度，从正例/反例推导 AC
2. 理解 design 接口和模块 -> 推导任务执行顺序，从模块边界推导文件范围

**验证输出**：输出前列出覆盖表：clarify 规则 -> 设计接口 -> Task -> 覆盖状态。如有规则无对应 Task -> 不能输出。

### Few-shot 示例

```
好的计划输出：
- 输入分析：3 个接口，数据模型 1 个，现有 src/models/ 有 5 个模型文件
- 决策：拆为 2 个任务，因为数据模型和 API 路由改动不同文件
- Task-1: 创建用户数据模型
  - 文件: src/models/user.py（修改）, tests/test_models/test_user.py（新建）
  - AC1: User.create(...) 成功返回 User 实例
  - AC2: User.create(username="te",...) 抛出 ValidationError
  - depends_on: []

坏的计划输出：
Task-1: 实现用户注册功能 / AC: 界面友好，性能良好 / 涉及文件: 用户相关文件
```

> 详见 L2 原文 行 1427-1526（完整 Few-shot 示例）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| AC 可测试性 | 存在无法翻译成 assert 的 AC |
| 任务粒度 | 单任务改动 > 5 文件 |
| 文件路径 | 未列出具体路径 |
| 依赖拓扑 | 存在循环依赖 |
| 需求覆盖 | 未覆盖全部功能点 |

### 输出前自检清单

1. 每条 clarify 规则 -> 是否都有对应的 Task 覆盖？（列出覆盖表）
2. 每个 AC 是否能翻译成一条 assert 语句或具体的测试场景？
3. 每个 Task 是否列出了具体的文件路径（基于 Glob 扫描）？
4. Task 之间是否有循环依赖？（画出依赖链确认）
5. 单个 Task 改动是否超过 5 个文件？（超过则需拆分）
6. 如果我做了任何假设，是否已标注？

### 评审上游：Design 审查

Planner 还承担 Design 文档评审。评审标准（DESIGN_OK vs DESIGN_ISSUE）：

| 检查项 | DESIGN_ISSUE 条件 |
|--------|------------------|
| clarify 规则覆盖 | 存在规则无对应接口/数据模型 |
| 接口完整性 | 缺少错误场景、参数校验 |
| 可执行性 | 模块边界模糊到无法拆分任务 |
| 过度设计 | 引入了未要求的抽象层 |
| 数据模型 | 无法支撑所有 clarify 正例的数据流 |

输出文件：`review_design_N.md`，格式含 `REVIEW: DESIGN_OK` 或 `REVIEW: DESIGN_ISSUE` + Issues 列表。

**自检清单（评审模式专用）**：
1. 是否逐条核对了 clarify 规则与 design 接口的对应关系？
2. 是否以"能否拆分为可执行任务"的视角审视设计粒度？
3. DESIGN_ISSUE 是否给出了具体位置和修改建议（而非泛泛的"不够完善"）？

---

## 4. Implementer（执行开发）— 4.3 节

**SubAgent**: `pipeline-implementer.md`
**引用 Skills**: `tdd-methodology`（主用）、`code-quality`（引用）
**工具**: Read, Write, Edit, Bash, Glob, Grep
**输入**: handoff_plan.md + handoff_design.md
**输出**: handoff_run.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 跳过 TDD | 先写实现再补测试 | 测试覆盖不全 |
| 虚假完成 | 代码是占位符 | Check/QA 大量失败 |
| 偏离设计 | 不按设计实现 | 模块边界混乱 |
| 一个大 commit | 所有改动一次提交 | 无法追溯回退 |

### 质量标准

- 严格 TDD：写测试 -> 运行确认失败 -> 写实现 -> 运行确认通过
- 一任务一 commit：message 格式 `feat(Task-N): 描述`，每 commit 必须包含测试
- 阻塞标注：无法完成标注 BLOCKED + 原因

### Few-shot 示例

```
好的执行输出：
- 输入分析：Task-1 要求创建用户模型，AC 3 条
- 决策：按设计文档校验规则实现（3-20 字符），不自行调整
- 测试先行：pytest -> 3 FAILED
- 实现：添加 username 字段 + validate_username
- 验证：pytest -> 3 PASSED
- Commit: feat(Task-1): 添加用户数据模型及校验

坏的执行输出：已完成用户模型开发，测试通过。
```

> 详见 L2 原文 行 1583-1639（完整 Few-shot）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 任务-commit 对应 | 存在任务无对应 commit |
| commit 含测试 | 存在不含测试的 commit |
| 完成度真实性 | 标记完成但测试未通过 |
| BLOCKED 说明 | BLOCKED 未说明原因 |
| 设计一致性 | 偏离设计接口定义 |

### 输出前自检清单

1. 每个 Task 是否都有对应的 commit？（列出 Task-commit 对照表）
2. 每个 commit 是否包含测试文件？
3. 是否有跳过 TDD 流程（先写实现再补测试）的情况？
4. 是否有标记 BLOCKED 但未说明原因的任务？
5. 实现是否偏离了 design 文档的接口定义？（逐接口核对）
6. 如果有任何遗留问题，是否已在 Handoff 中明确标注？

### 评审上游：Plan 审查

Implementer 还承担 Plan 文档评审。评审标准（PLAN_OK vs PLAN_ISSUE）：

| 检查项 | PLAN_ISSUE 条件 |
|--------|-----------------|
| 文件路径 | 引用路径不存在（Glob 验证） |
| AC 可测性 | 无法翻译为 assert |
| 依赖拓扑 | 存在循环或顺序矛盾 |
| 任务粒度 | 单任务 > 5 文件 |
| 设计一致性 | 与 handoff_design.md 矛盾 |

输出文件：`review_plan_N.md`。

**自检清单（评审模式专用）**：
1. 是否逐条核对了每个任务的文件路径是否真实存在（通过 Glob 验证）？
2. 是否以"能否翻译为 assert"的视角审视每个 AC？
3. PLAN_ISSUE 是否给出了具体位置和修改建议（而非泛泛的"不够完善"）？

---

## 5. Checker（代码检查）— 4.4 节

**SubAgent**: `pipeline-checker.md`
**引用 Skills**: `code-quality`（主用）、`review-standard`（主用）
**工具**: Read, Bash, Glob, Grep（只读，不能修改代码）
**输入**: handoff_plan.md + handoff_run.md
**输出**: handoff_check.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 只跑测试 | 测试通过就 PASS | 代码质量问题漏到 QA |
| 主观判断 | "代码看起来不错" | 不可验证 |
| 不对照 AC | 只做通用检查 | 功能遗漏未发现 |
| 漏掉维度 | 忘了 lint 或 type 检查 | 低级问题遗留 |

### 质量标准：五维检查

1. **测试**：运行全量测试，记录通过/失败数
2. **Lint**：运行 ruff/eslint，记录告警数
3. **类型检查**：运行 mypy/tsc（如配置了）
4. **代码质量规则**：函数 <= 40 行、参数 <= 5 个、嵌套 <= 3 层、无空 catch、无裸 except、无硬编码
5. **AC 覆盖**：逐条核对计划中每个任务的 AC

- 每项必须有客观证据：命令输出、文件路径:行号、具体数值
- 结论只有 PASS/FAIL，五维全 PASS 才是 PASS
- **注意**：Checker 只描述问题，PASS/FAIL 判定由 pipeline.sh 独立运行测试决定

### Few-shot 示例

```
好的检查输出：
1. 测试: pytest -> 47 passed, 2 failed（列出 FAIL 详情）
2. Lint: ruff check -> 3 warnings（列出每条）
3. 类型检查: mypy -> 0 errors
4. 代码质量: create_user() 6 个参数（超标，路径:行号）
5. AC 覆盖: 逐条表格（Task/AC/状态/证据）
RESULT: FAIL（测试 2 FAIL + 代码质量 1 FAIL）

坏的检查输出：代码质量良好，测试基本通过。PASS
```

> 详见 L2 原文 行 1695-1794（完整 Few-shot 和 AC 覆盖表格示例）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 五维完整性 | 缺少任何一个维度 |
| FAIL 项证据 | 缺少文件路径和行号 |
| 客观性 | 存在主观描述 |
| AC 逐条覆盖 | 未逐条列出状态 |

---

## 6. QA（验收测试）— 4.5 节

**SubAgent**: `pipeline-qa.md`
**引用 Skills**: `qa-methodology`（主用）
**工具**: Read, Bash, Glob, Grep（只读，不能修改代码）
**输入**: handoff_clarify.md（唯一验收标准） + handoff_design.md（接口信息）
**输出**: handoff_qa.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 重复 Check 工作 | 又跑一遍测试和 lint | 浪费资源 |
| 标准偏移 | 以 plan/design 为验收标准 | 验收的是"计划"非"需求" |
| 只验正常路径 | 不测边界条件 | 用户遇到未处理场景 |
| 测试通过=功能正确 | Check 通过就等于满足需求 | "代码正确" != "功能正确" |

### 质量标准

- 验收标准唯一来源：handoff_clarify.md
- 接口信息来源：handoff_design.md（仅用于获取路径和参数格式）
- 与 Check 分工：Check 验证"代码质量"，QA 验证"功能是否满足需求"
- 逐条需求覆盖：每条规则及正例/反例，逐条 PASS/FAIL + 证据
- 边界条件必测：排除项和边界条件也验证
- 端到端视角：从用户使用角度验证
- 验证方式：启动真实服务 -> 健康检查 -> 端到端测试 -> 停止服务
- **注意**：QA 只描述问题，PASS/FAIL 判定由 pipeline.sh 独立运行测试决定

### Few-shot 示例

```
好的 QA 输出：
- 输入分析：clarify F1 用户注册 3 条规则 + 排除项
- 决策：以 clarify 为唯一标准，独立端到端验证
- 逐条验收表格（规则/期望/实际/状态/验证方式）
- FAIL 详情：期望 422 / 实际 500 / 复现命令 curl ...
RESULT: FAIL

坏的 QA 输出：测试全部通过，功能正常。PASS
```

> 详见 L2 原文 行 1797-1880（完整 Few-shot 和逐条验收表格）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 验收标准来源 | 未以 clarify 为唯一标准 |
| 功能点覆盖 | 功能点未全部覆盖 |
| FAIL 项三要素 | 缺少期望行为/实际行为/复现方式 |
| 边界条件 | 未验证边界和排除项 |
| 与 Check 差异化 | 验证方式与 Check 重复 |

---

## 7. Fixer（修复）— 4.6 节

**SubAgent**: `pipeline-fixer.md`
**引用 Skills**: `tdd-methodology`（主用）、`code-quality`（引用）
**工具**: Read, Write, Edit, Bash, Glob, Grep
**输入**: handoff_qa.md + handoff_check.md
**输出**: handoff_fix_N.md

### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| 创可贴修复 | 只消除症状 | 问题换形式再现 |
| 重复失败方案 | 第 3 次还用第 1 次方法 | 死循环 |
| 降级修复 | 删除测试、降低标准 | 质量倒退 |
| 修一坏二 | 修复引入新 Bug | 越修越多 |

### 质量标准

- 根因分析：每个 FAIL 项先分析根因
- 差异说明（N > 1）：说明上次为什么失败、这次方案有何不同
- 最小修改：只改必要代码
- 回归测试：每个修复附回归测试
- 修复后自验：运行测试确认通过再输出

### Few-shot 示例

```
好的修复输出：
- 输入分析：1 个 FAIL（密码少于 8 位返回 500 期望 422），第 1 次修复
- 根因：src/api/v1/users.py:35 未调用 User.validate()
- 修复：添加 User.validate(data) 调用
- 验证：修复前 FAILED(500) / 修复后 PASSED(422) / 全量 49 passed 0 failed

坏的修复输出：已修复密码校验问题。测试通过。
```

> 详见 L2 原文 行 1883-1963（完整 Few-shot 和修复前后 diff）

### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 根因分析 | FAIL 项缺少根因分析 |
| 差异说明（N > 1） | 未说明与上次差异 |
| 降级检测 | 涉及删除测试或降低标准 |
| 回归测试 | 未添加回归测试 |
| 修复有效性 | 修复后测试未通过 |
| 回归安全 | 修复引入新测试失败 |

---

## 8. Ship（交付）— 4.7 节

**Skill 入口**: `/ship`（现有）
**工具**: Read, Bash
**输入**: handoff_clarify.md + handoff_qa.md
**输出**: PR URL

需用户确认后执行（不可逆操作），不纳入自动编排。
完成后清理进度文件，Pipeline 目录移至 `docs/pipeline/archive/`。
