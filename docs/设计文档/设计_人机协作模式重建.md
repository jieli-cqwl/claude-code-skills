# 设计：Claude Code 人机协作模式重建

**设计日期**：2026-02-13
**需求文档**：`docs/需求澄清/clarify_人机协作模式重建.md`
**调研依据**：`docs/设计文档/调研_Claude_Code_CLI编排能力.md`、`docs/设计文档/调研_流程编排社区方案.md`

---

## 1. 架构总览

### 1.1 核心思路

Shell 脚本（`pipeline.sh`）作为编排器，依次调用 `claude -p` 执行每个环节。每次 `claude -p` 调用注入对应 Subagent 的 prompt，拥有独立上下文窗口。流程控制（顺序、循环、条件判断）在 bash 中确定性执行，不依赖 LLM。CLI 命令可配置（`claude` / `claude-codex` / `claude-gemini`），无缝支持多 backend。

```
用户输入需求
    ↓
/clarify（用户深度参与，交互式会话）
    ↓ 输出: {project}/docs/pipeline/{feature}/handoff_clarify.md
    ↓
用户："开始" / "交给你了"
    ↓
Claude 后台启动: nohup pipeline.sh "{feature}" "{project_dir}" &
    ↓
┌──────────────────────────────────────────────────────────────┐
│  pipeline.sh (bash 脚本，确定性流程控制)                       │
│                                                              │
│  ┌─ Design-Plan 循环（最多 3 轮） ────────────────────────┐  │
│  │  $CLI_CMD -p [designer]  → handoff_design              │  │
│  │  $CLI_CMD -p [planner 审查 design]                     │  │
│  │  bash: 解析 DESIGN_OK / DESIGN_ISSUE                   │  │
│  │  ├─ DESIGN_OK → 继续                                   │  │
│  │  └─ DESIGN_ISSUE → 回调 designer 修正 → 重新审查       │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
│  ⏸️ 可选人工确认（HUMAN_CHECKPOINT，默认开启）                │
│                                                              │
│  ┌─ Plan-Implement 循环（最多 3 轮） ────────────────────┐  │
│  │  $CLI_CMD -p [planner]   → handoff_plan               │  │
│  │  $CLI_CMD -p [implementer 审查 plan]                  │  │
│  │  bash: 解析 PLAN_OK / PLAN_ISSUE                      │  │
│  │  ├─ PLAN_OK → 继续                                    │  │
│  │  └─ PLAN_ISSUE → 回调 planner 修正 → 重新审查         │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌─ Implement-Check 循环（最多 3 轮） ───────────────────┐  │
│  │  $CLI_CMD -p [implementer] → handoff_run              │  │
│  │  $CLI_CMD -p [checker]   → handoff_check              │  │
│  │  bash: 独立运行 pytest/npm test → PASS / FAIL        │  │
│  │  ├─ CHECK_PASS → 继续                                 │  │
│  │  └─ CHECK_FAIL → $CLI_CMD -p [fixer] → 重新 check    │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌─ QA-Fix 循环（最多 10 轮） ───────────────────────────┐  │
│  │  $CLI_CMD -p [qa: 启动真实服务 → 端到端验证 → 停服务]  │  │
│  │  bash: 独立运行 pytest/npm test → PASS / FAIL        │  │
│  │  ├─ PASS → 通知 → 退出                                │  │
│  │  └─ FAIL → $CLI_CMD -p [fixer] → [checker] → 重新 QA │  │
│  │           → ≥5 轮暂停人工 → ≥10 轮终止                │  │
│  └────────────────────────────────────────────────────────┘  │
└──────────────────────────────────────────────────────────────┘
    ↑ 写入                    ↑ 读取
    .pipeline-progress-{feature}.json  Status Line（UI 状态栏被动显示）
                              /status Skill（详情查询）
    ↓
用户验收（通过 Status Line 看到 PASS，或收到系统通知）
    ↓
/ship（用户确认后执行）
```

**确定性逻辑用确定性工具**：流程控制（步骤顺序、文件检查、循环计数、PASS/FAIL 判断）在 bash 中执行，不交给 LLM。LLM 只负责每个环节内的实际工作。

**进度可见性**：pipeline.sh 每步写入 `.pipeline-progress-{feature}.json`（按 feature 隔离），Claude Code 的 Status Line 自动读取并在 UI 状态栏显示当前步骤。用户无需主动询问，被动实时可见，零 token 开销。

### 1.2 双模式架构

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

同一套 SubAgent 文件 + 同一套 Skills（方法论），两种触发方式：

```
手动模式: /design Skill (context: fork, agent: pipeline-designer) → 隔离上下文中执行
自动模式: pipeline.sh → claude -p "$(cat pipeline-designer.md + skills) ..." → 独立进程执行
                                        ↑
                                  同一份 SubAgent 文件（精简角色卡，< 3k tokens）
                                + 同一套 Skills（方法论知识层，通过 skills 字段声明引用）
```

| 模式 | 触发方式 | 执行机制 | Skills 加载方式 | 适用场景 |
|------|---------|---------|----------------|---------|
| **手动** | 用户在交互式会话中 `/design`、`/check` 等 | Skill 声明 `context: fork` + `agent` 字段，在隔离上下文中执行 SubAgent | SubAgent 的 `skills` 字段自动注入 | 改 Bug、单步执行、调试某个环节 |
| **自动** | `/clarify` 完成后用户说"开始" | `pipeline.sh` → 多次 `claude -p` | pipeline.sh 手动拼接 SubAgent + Skills 内容（CLI 模式不支持 `skills` 字段自动注入） | 完整功能开发，用户只管首尾 |

**三层架构**：
- **Skills（知识层）**：方法论、经验、质量标准的可复用沉淀（如 TDD 方法论、代码质量标准），多个 SubAgent 可共享引用
- **SubAgents（执行层）**：精简角色卡（< 3k tokens），只包含角色身份 + 行为边界 + 输入输出规范，通过 `skills` 字段引用知识层
- **pipeline.sh（编排层）**：确定性流程控制，不关心方法论内容

**手动与自动模式的 Skills 加载差异**：
- 手动模式：SubAgent 文件中的 `skills` 字段由 Claude Code 原生机制自动解析，Skills 内容在 SubAgent 启动时完整注入上下文
- 自动模式（`claude -p`）：CLI 模式下 `skills` 字段不被自动解析。pipeline.sh 需要在构建 prompt 时手动读取并拼接 Skills 内容（`$(cat agent.md) + $(cat skill1.md) + $(cat skill2.md)`）。这确保两种模式下 SubAgent 获得完全相同的知识

### 1.3 用户交互设计

用户不需要记任何命令。整个流程通过自然对话触发：

**场景 1：完整功能开发**
```
用户："我要做一个用户管理功能"
Claude：进入 /clarify 深度澄清
  ... 多轮对话 ...
Claude："需求已澄清，文档已输出到 docs/pipeline/用户管理/handoff_clarify.md。要启动自动开发流程吗？"
用户："开始" / "好" / "交给你了"
Claude：Bash(后台) → nohup pipeline.sh "用户管理" "/path/to/project" &
Claude："Pipeline 已在后台启动。状态栏会显示实时进度，完成后系统通知你。"
  ... Pipeline 独立运行，与当前会话无关 ...
  ... 状态栏: [Pipeline: 用户管理 | implement 3/6 | 12m] ...
  ... 用户随时可说 /status 查看详情 ...
系统通知："用户管理 - QA 验收通过，请查看结果"
用户（新会话或同一会话）：查看留痕文档 → /ship
```

**场景 2：单步手动**
```
用户："帮我检查一下代码质量"
Claude：执行 /check（内部通过 Task 工具调用 pipeline-checker Subagent）

用户："这个 Bug 帮我修一下"
Claude：直接修复（不走 pipeline，用现有能力）

**场景 3：交互式评审（新增）**
```
Pipeline 暂停在 Design 阶段："等待确认 handoff_design.md"
用户："./pipeline.sh review design"
Claude (进入 Designer 上下文)："您好，我是架构师。请问对设计文档有何修改建议？"
用户："数据库索引漏了 user_id"
Claude："收到，已更新设计文档。请再次确认。"
用户："确认" → Pipeline 继续
```
```

**触发规则**：
- `/clarify` 完成后，主动提示是否启动自动流程
- 用户任何表达"开始"、"做吧"、"交给你"意图的自然语言 → 后台启动 `pipeline.sh`
- `pipeline.sh` 启动后是独立进程，不依赖当前 Claude Code 会话
- 单步 Skill 随时可用，不影响 pipeline

### 1.4 设计原则

| 原则 | 说明 |
|------|------|
| **独立上下文** | 每个 Subagent 拥有独立上下文窗口，天然隔离 |
| **文档留痕** | 每步输出结构化 Handoff 文档，可追溯 |
| **失败即停** | 任何环节异常暂停通知用户，禁止降级 |
| **工具最小化** | 每个 Subagent 只开放必要的工具权限 |
| **三层分离** | SubAgent（角色卡）+ Skills（方法论）+ pipeline.sh（编排），各层职责清晰 |

### 1.5 前置验证（已通过）

**验证 1**：`claude -p` 中通过 Task 工具调用 Custom Subagent → ✅ 通过（26 秒，Subagent 成功读取输入文件并写入输出文件）

**验证 2**：单次 `claude -p` 中链式调用多个 Subagent → ✅ 通过（398 秒，编排器依次调用 test-agent → test-agent-b，Handoff 文档成功串联）

**架构决策**：验证证明 Task + Subagent 机制可行，但也暴露了链式调用的耗时问题（2 步就 400 秒）。结合可靠性分析（LLM 做流程控制不如 bash 确定性），最终选择 Shell 脚本编排器 + 多次 `claude -p` 方案。每步仍是独立的 `claude -p` 调用（独立上下文），Subagent 文件仍是质量标准的唯一来源。

**验证 3（待完成）**：`claude -p --permission-mode plan` 在非交互模式下正常执行 → ⏳ 待验证。plan 模式通常需要用户审批，需确认在 `-p` 下是否自动跳过审批或正常退出。此验证为 Go-Live 阻断项。

### 1.6 已知风险与防护

| 风险 | 来源 | 防护措施 |
|------|------|---------|
| CLI 进程挂死 | 已知 Bug（Issue #19060, #24478, #19498） | 双重防护：使用系统的 `timeout` 或 macOS `gtimeout` 配合 `--signal=KILL` 强制清理整个进程树 + `--max-budget-usd` 费用上限 |
| 单步费用失控 | Subagent 陷入无效循环 | 每步 `claude -p` 使用 `--max-budget-usd` 限制单步费用 |
| 同一 feature 重复启动 | 用户误操作 | `pipeline.sh` 启动时检查锁文件，防止同一 feature 并行 |
| Handoff 文件残留 | 上次 Pipeline 未清理 | `pipeline.sh` 启动时检查目录是否已有 Handoff 文件，提示用户清理。支持 `pipeline.sh reset {feature}` 子命令一键清理（删除除 handoff_clarify.md 外的所有 Handoff 文件 + 进度文件 + 锁文件） |
| Implement 中途失败后代码状态 | Implementer 有全权限写代码和 commit | Implementer 的 handoff_run.md 交接项中包含 `commit_hashes` 字段。pipeline.sh 在 implement 失败时通知用户"Implement 阶段产生了 N 个 commit（hash 列表），请自行决定是否保留"。pipeline.sh 不做自动回滚（破坏性操作需人工确认） |
| feature name Unicode 正则兼容性 | macOS bash 3.2 不支持 `\x{4e00}` | 已通过改用 `perl -e` 正则解决（macOS 自带 perl 5.x 完整支持 Unicode） |
| `timeout` 子进程强制清理 | 测试框架可能在后台启动孤儿进程 | 直接利用 `timeout --signal=KILL` 取代原来的 `perl alarm` 的半吊子清理。当到达设定上限时间时，会通过系统向全进程组广播 KILL 信号，彻底阻止孤儿端口/内存锁死 |

**已通过架构设计消除的风险**：
- ~~编排器上下文溢出~~：Shell 脚本编排器不消耗 LLM 上下文
- ~~macOS 无 timeout~~：通过安装 `coreutils` 引用 `gtimeout --signal=KILL`，配合 `setsid` 进程组隔离，实施全进程树强杀。

---

### 1.7 P2 配置质量（已完成）

需求文档中 P2 问题是"配置质量"——31 Skills / 14 Hooks / 194 行 Rules 存在形式主义。已通过以下方式解决：

**Skills 精简（31 → 19）**，删除 14 个 + 新增 2 个：

第一批删除（9 个，已完成）：
- 被 Pipeline 替代：自动开发_auto-dev、开发循环_dev-loop、设计循环_design-loop、需求循环_req-loop
- 被 Subagent 架构替代：专家协作_experts、并行调度_parallel
- 冗余/低价值：创建技能_new-skill、重构Java_refactor-java、重构Python_refactor-py

第二批删除（5 个）：
- Gemini评审_gemini-critique：Pipeline 已有 Checker + QA 双重独立质量门控，Gemini 评审边际价值低；需求排除项"不追求自己挑战自己替代多视角"
- 方案评审_critique：LLM 评审 LLM 的设计输出，与排除项冲突；质量保障来自 Subagent prompt 的角色张力，不是加评审层
- 测试生成_test-gen：被 Implementer 的严格 TDD 流程吸收（先写测试→确认失败→写实现→确认通过）
- 方案探索_explore：Designer Subagent 已包含扫描现有代码 + 多方案对比；深度调研在 clarify 阶段沟通
- 调试_debug：合并到 /fix（pipeline-fixer），fix 同时支持手动和自动模式

新增 2 个：
- /fix：pipeline-fixer Subagent 入口，手动/自动模式均可使用
- /status：读取 `.pipeline-progress-{feature}.json` 展示进度详情

**Hooks 精简（12 → 8）**，删除 4 个 + 重写 1 个：
- research_tracker.sh：Pipeline Handoff 文档替代其记录功能
- brain_switch.sh：未启用，无实际用途
- claude_slavery.sh：未启用，无实际用途
- completion_check.sh：验证 Claude 自己标记的 checkbox，是形式主义（虚假完成的"认证者"而非"检查者"），由 Pipeline 编排器的实质验证替代
- code_quality_check.sh：从 50+ 规则精简到 ~12 条安全/资源类规则，移除所有"判断类"规则（降级、Mock、N+1 等），质量判断交给 Subagent 语义检查

**Hooks 职责边界重新定义**：
- Hook 只做安全防线（危险命令、凭证保护、安全漏洞）和机械自动化（格式化、快照）
- 质量判断（代码正确性、需求偏差、虚假完成）交给 Subagent（pipeline-checker、pipeline-qa）
- 核心原则：不用 bash/grep/regex 解决需要 LLM 判断力的问题

**Skill 改造**：流程相关 Skill 使用 `context: fork` + `agent` 字段声明式引用 SubAgent，同时回归方法论载体角色（知识层）
**三层架构**：Skills（方法论知识层）+ SubAgents（精简角色卡）+ pipeline.sh（编排层），方法论跨 SubAgent 复用，消除冗余

---

## 2. 目录结构

```
~/.claude/
├── agents/                            # SubAgent 定义（精简角色卡，< 3k tokens 每个）
│   ├── pipeline-designer.md           # 架构设计（skills: [architecture]）
│   ├── pipeline-planner.md            # 开发计划（skills: [architecture, review-standard]）
│   ├── pipeline-implementer.md        # 执行开发（skills: [tdd-methodology, code-quality]）
│   ├── pipeline-checker.md            # 代码检查（skills: [code-quality, review-standard]）
│   ├── pipeline-qa.md                 # 验收测试（skills: [qa-methodology]）
│   └── pipeline-fixer.md              # 修复（skills: [tdd-methodology, code-quality]）
├── pipeline.sh                        # Shell 脚本编排器（含 build_prompt Skills 拼接逻辑）
├── skills/
│   ├── pipeline-architecture/         # Skills 知识层：架构设计方法论
│   │   └── SKILL.md
│   ├── pipeline-tdd-methodology/      # Skills 知识层：TDD 流程
│   │   └── SKILL.md
│   ├── pipeline-code-quality/         # Skills 知识层：代码质量标准
│   │   └── SKILL.md
│   ├── pipeline-review-standard/      # Skills 知识层：代码审查标准
│   │   └── SKILL.md
│   ├── pipeline-qa-methodology/       # Skills 知识层：QA 验收方法论
│   │   └── SKILL.md
│   └── pipeline-status/               # /status Skill（新增）
│       └── SKILL.md

项目根目录/
├── .pipeline-progress-{feature_name}.json  # 进度文件（pipeline.sh 每步写入，按 feature 隔离）
└── docs/
    └── pipeline/
        ├── {feature_name}/            # 每个需求一个命名空间
        │   ├── handoff_clarify.md
        │   ├── handoff_design.md
        │   ├── review_design_N.md       # Planner 对 Design 的评审（N = 轮次编号）
        │   ├── handoff_plan.md
        │   ├── review_plan_N.md        # Implementer 对 Plan 的评审（N = 轮次编号）
        │   ├── handoff_run.md
        │   ├── handoff_check.md
        │   ├── handoff_qa.md
        │   ├── handoff_fix_pre_N.md    # N = QA 前的 Check 修复迭代次数
        │   └── handoff_fix_N.md        # N = QA 后的修复迭代次数
        └── archive/                   # 已完成的 Pipeline
            └── {feature_name}/
```

**说明**：
- SubAgent 文件放 `~/.claude/agents/`，全局可用（跨项目共享），每个文件 < 3k tokens（精简角色卡）
- Skills 知识层放 `~/.claude/skills/pipeline-*/`，全局可用，SubAgent 通过 `skills` 字段引用
- `pipeline.sh` 放 `~/.claude/`，全局可用，接受项目目录参数，内含 `build_prompt()` 自动拼接 Skills
- `.pipeline-progress-{feature_name}.json` 放项目根目录，按 feature 隔离，Status Line 读取最近更新的文件显示进度
- Handoff 文档放项目内 `docs/pipeline/{feature_name}/`，按 feature 隔离
- 不同 feature 的 Pipeline 可并行运行，互不干扰
- `/ship` 完成后，Pipeline 目录移至 `docs/pipeline/archive/`

---

## 3. 编排器设计（pipeline.sh）

### 3.1 角色与职责

`pipeline.sh` 是一个 bash 脚本，作为整个流程的编排器。职责：

- **确定性流程控制**：步骤顺序、文件检查、循环计数、PASS/FAIL 判断，全部在 bash 中执行
- **调用 LLM 执行实际工作**：每步通过 `claude -p` 调用对应 Subagent，传入 Handoff 文件路径
- **异常检测与通知**：每步检查退出码和输出文件，异常时发送系统通知（macOS osascript / Linux notify-send）
- **并行隔离**：通过 feature name 参数和锁文件机制，支持多个 Pipeline 并行

**不做的事**：pipeline.sh 不解析 Handoff 文件内容、不做质量判断、不理解业务逻辑。这些全部交给各 Subagent。

### 3.2 触发方式

**方式 1：/clarify 完成后自动触发（推荐）**

```
用户完成 /clarify → Claude 提示"要启动自动开发流程吗？"
用户："开始" → Claude 通过 Bash 工具后台执行：
nohup ~/.claude/pipeline.sh "用户管理" "$(pwd)" &
```

pipeline.sh 作为独立进程运行，不依赖当前 Claude Code 会话。用户可以关闭会话或继续其他工作。

**方式 2：用户手动命令行（备用）**

```bash
# 默认用 claude
~/.claude/pipeline.sh "用户管理" /path/to/project

# 用 Codex 作为 backend
CLI_CMD=claude-codex ~/.claude/pipeline.sh "用户管理" /path/to/project
```

### 3.3 脚本核心逻辑

```bash
#!/bin/bash
set -euo pipefail

FEATURE="$1"
PROJECT_DIR="${2:-.}"                  # 第二个参数：项目目录，默认当前目录

# --- feature name 合法性校验（用 perl 正则，兼容 macOS bash 3.2 的 Unicode） ---
if ! perl -e 'exit(0) if $ARGV[0] =~ /^[\w\-\x{4e00}-\x{9fff}]+$/u; exit(1)' "$FEATURE"; then
  echo "ERROR: feature name 只允许中文、英文、数字、下划线、连字符，不允许空格和特殊字符"
  exit 1
fi
CLI_CMD="${CLI_CMD:-claude}"           # 环境变量：CLI 命令（claude / claude-codex / claude-gemini）
AGENTS_DIR="$HOME/.claude/agents"
MAX_FIX=10
MAX_REVIEW=${MAX_REVIEW:-3}           # Design-Plan / Plan-Implement 评审最大轮数
MAX_CHECK_LOOP=${MAX_CHECK_LOOP:-3}   # Implement-Check 修复循环最大轮数（QA 前）
STEP_BUDGET=10.00                     # 单步费用上限
STEP_TIMEOUT=1800                     # 单步超时（秒），防止 CLI 进程挂死
TOTAL_STEPS=6                         # 主步骤数（design, plan, implement, check, qa, fix），评审轮数不计入
TOTAL_BUDGET=${TOTAL_BUDGET:-200.00}  # 总费用安全网（默认 $200），首批 3 个需求后根据实际费用数据调整阈值
HUMAN_CHECKPOINT=${HUMAN_CHECKPOINT:-true}   # 默认开启。Design/Plan 是方向性决策，跑偏代价远超代码层面。前 10 个需求建议保持开启，积累信心后可关闭

# 切换到项目目录（所有相对路径基于项目根目录）
cd "$PROJECT_DIR"

PIPELINE_DIR="docs/pipeline/${FEATURE}"
PROGRESS_FILE=".pipeline-progress-${FEATURE}.json"
START_TIME=$(date +%s)
START_TIME_ISO=$(date '+%Y-%m-%dT%H:%M:%S')  # 启动时一次性格式化，避免 date -r/-d 跨平台差异

# --- 通知函数（macOS osascript + Linux notify-send 回退） ---
notify() {
  if command -v osascript &>/dev/null; then
    osascript -e "display notification \"$2\" with title \"$1\" sound name \"Glass\"" 2>/dev/null || true
  elif command -v notify-send &>/dev/null; then
    notify-send "$1" "$2" 2>/dev/null || true
  fi
  echo "[NOTIFY] $1: $2"  # 始终输出到日志
}
notify_error() {
  if command -v osascript &>/dev/null; then
    osascript -e "display notification \"$2\" with title \"$1\" sound name \"Basso\"" 2>/dev/null || true
  elif command -v notify-send &>/dev/null; then
    notify-send -u critical "$1" "$2" 2>/dev/null || true
  fi
  echo "[ERROR-NOTIFY] $1: $2"  # 始终输出到日志
}

# --- 人工确认函数（Design/Plan 方向性决策暂停等待用户确认） ---
wait_for_confirmation() {
  local step_name="$1"
  local handoff_file="$2"
  local confirm_file="${PIPELINE_DIR}/.confirm-${step_name}"

  update_progress "$step_name" "$step_index" "waiting-confirmation"
  notify "Pipeline" "${FEATURE} ${step_name} 完成，请 Review ${handoff_file} 后确认"

  echo "=== 等待人工确认 ${step_name} ==="
  echo ">>> 请查看 ${handoff_file}"
  echo ">>> 确认后执行: touch ${confirm_file}"
  echo ">>> 需修改请执行: ./pipeline.sh review ${step_name} (进入交互式评审)"
  echo ">>> 拒绝请执行: echo 'REJECT: 原因' > ${confirm_file}"

  # 轮询等待确认文件（每 30 秒检查一次，最长等 24 小时）
  local max_wait=86400
  local waited=0
  while [ ! -f "$confirm_file" ] && [ $waited -lt $max_wait ]; do
    sleep 30
    waited=$((waited + 30))
  done

  if [ ! -f "$confirm_file" ]; then
    update_progress "$step_name" "$step_index" "confirmation-timeout"
    notify_error "Pipeline" "${step_name} 确认超时（24h）"
    exit 1
  fi

  if grep -q "^REJECT" "$confirm_file"; then
    local reason=$(sed 's/^REJECT: //' "$confirm_file")
    update_progress "$step_name" "$step_index" "rejected"
    notify_error "Pipeline" "${step_name} 被拒绝: ${reason}"
    rm -f "$confirm_file"
    exit 1
  fi

  rm -f "$confirm_file"
  echo "=== ${step_name} 已确认，继续 ==="
}

# --- Handoff 结构化验证（最低限度格式检查，非质量保证） ---
# 注意：此函数使用 grep 关键词匹配，只能拦截"明显缺失"（如 Design 文档完全没提接口），
# 无法判断内容质量（如接口定义是否完整）。质量判断交给 Subagent 自检 + 评审循环 + 人工确认。
# LLM 可以轻易满足关键词匹配（在文档中写一句"本设计涉及接口"即过检），
# 因此此函数定位为"最低限度格式兜底"，不是质量门控的核心。
validate_handoff() {
  local step_name="$1"
  local output_file="$2"
  local warnings=""

  case "$step_name" in
    design)
      grep -q "接口\|API\|endpoint\|interface" "$output_file" || warnings="${warnings}\n- 缺少接口定义"
      grep -q "方案.*对比\|方案 A\|方案 B\|备选" "$output_file" || warnings="${warnings}\n- 缺少多方案对比"
      ;;
    plan)
      grep -q "Task-[0-9]\|任务.*[0-9]" "$output_file" || warnings="${warnings}\n- 缺少具体 Task 编号"
      grep -qi "AC[0-9]\|AC:" "$output_file" || warnings="${warnings}\n- 缺少验收标准(AC)"
      grep -q "depends_on\|依赖" "$output_file" || warnings="${warnings}\n- 缺少依赖关系说明"
      ;;
    implement*)
      grep -qi "commit\|提交" "$output_file" || warnings="${warnings}\n- 缺少 commit 记录"
      grep -qi "passed\|failed\|pytest\|test" "$output_file" || warnings="${warnings}\n- 缺少测试运行记录"
      ;;
    check*)
      grep -qi "测试" "$output_file" || warnings="${warnings}\n- 缺少测试检查维度"
      grep -qi "lint" "$output_file" || warnings="${warnings}\n- 缺少 Lint 检查维度"
      grep -qi "AC.*覆盖\|AC 覆盖" "$output_file" || warnings="${warnings}\n- 缺少 AC 覆盖检查"
      ;;
    fix*)
      grep -q "根因\|root.*cause\|原因分析" "$output_file" || warnings="${warnings}\n- 缺少根因分析"
      ;;
  esac

  if [ -n "$warnings" ]; then
    echo "ERROR: ${step_name} Handoff 结构验证失败，强行中断:${warnings}"
    notify_error "Pipeline" "${step_name} 关键输出缺失，验证失败并中止！"
    exit 1
  fi
}

# --- 费用累计检查（预留接口：待 claude -p 支持 cost 输出后启用） ---
# 当前 claude -p 不输出 session cost，TOTAL_COST 暂为估算值（步数 × STEP_BUDGET）。
# 待 claude -p 支持 --output-format json 包含 cost_usd 字段后，改为实际费用累加。
TOTAL_COST=0  # 费用累加器（当前为步骤计数 × STEP_BUDGET 估算）
step_count_for_budget=0
check_budget() {
  step_count_for_budget=$((step_count_for_budget + 1))
  TOTAL_COST=$(echo "$step_count_for_budget * $STEP_BUDGET" | bc)
  if (( $(echo "$TOTAL_COST > $TOTAL_BUDGET" | bc -l) )); then
    notify_error "Pipeline" "估算费用 \$${TOTAL_COST}（${step_count_for_budget} 步 × \$${STEP_BUDGET}）超过总预算 \$${TOTAL_BUDGET}，暂停"
    wait_for_confirmation "budget-exceeded" "${PROGRESS_FILE}"
  fi
}

# --- 进度文件写入（原子操作：先写临时文件再 mv，防止读取方读到半写入数据） ---
update_progress() {
  local step_name="$1"
  local step_index="$2"
  local status="$3"   # running / completed / failed
  local elapsed=$(( $(date +%s) - START_TIME ))
  local tmp_file="${PROGRESS_FILE}.tmp.$$"
  cat > "$tmp_file" <<EOF
{
  "schema_version": 1,
  "feature": "${FEATURE}",
  "current_step": "${step_name}",
  "step_index": ${step_index},
  "total_steps": ${TOTAL_STEPS},
  "status": "${status}",
  "fix_count": ${fix_count:-0},
  "total_cost_usd": ${TOTAL_COST:-0},
  "elapsed_seconds": ${elapsed},
  "started_at": "${START_TIME_ISO}",
  "updated_at": "$(date '+%Y-%m-%dT%H:%M:%S')",
  "cli_backend": "${CLI_CMD}"
}
EOF
  mv "$tmp_file" "$PROGRESS_FILE"
}

# --- 环境依赖检查（Go-Live 准入条件之一） ---
preflight_check() {
  local missing=""
  # jq：Status Line 依赖 jq 解析 JSON
  if ! command -v jq &>/dev/null; then
    missing="${missing}\n  - jq (brew install jq)"
  fi
  # gtimeout / timeout：进程超时强杀
  if ! command -v gtimeout &>/dev/null && ! command -v timeout &>/dev/null; then
    missing="${missing}\n  - coreutils (brew install coreutils) — 提供 gtimeout"
  fi
  # setsid：进程组隔离
  if ! command -v setsid &>/dev/null; then
    missing="${missing}\n  - util-linux (brew install util-linux) — 提供 setsid"
  fi
  if [ -n "$missing" ]; then
    echo "ERROR: 缺少必要依赖，请先安装：${missing}"
    exit 1
  fi
}
preflight_check

# --- 前置检查（先验证环境，再创建锁文件） ---
if [ ! -f "${PIPELINE_DIR}/handoff_clarify.md" ]; then
  echo "ERROR: ${PIPELINE_DIR}/handoff_clarify.md 不存在，请先执行 /clarify"
  notify_error "Pipeline" "handoff_clarify.md 不存在"
  exit 1
fi

# 残留文件检查（防止上次 Pipeline 未清理的文件干扰本次执行）
for f in handoff_design.md handoff_plan.md handoff_run.md handoff_check.md handoff_qa.md; do
  if [ -f "${PIPELINE_DIR}/${f}" ]; then
    echo "ERROR: 检测到残留文件 ${PIPELINE_DIR}/${f}，请先清理上次 Pipeline 的输出"
    notify_error "Pipeline" "检测到残留 Handoff 文件，请清理后重试"
    exit 1
  fi
done
if ls "${PIPELINE_DIR}"/handoff_fix_*.md 2>/dev/null | head -1 > /dev/null; then
  echo "ERROR: 检测到残留 fix 文件，请先清理上次 Pipeline 的输出"
  notify_error "Pipeline" "检测到残留 handoff_fix 文件，请清理后重试"
  exit 1
fi

# 锁文件（mkdir 原子操作，解决并发竞态）
LOCK_DIR="${PIPELINE_DIR}/.lock.d"
if ! mkdir "$LOCK_DIR" 2>/dev/null; then
  echo "ERROR: ${FEATURE} 已有 Pipeline 在运行（锁目录: $LOCK_DIR）"
  notify_error "Pipeline" "${FEATURE} 已有 Pipeline 在运行"
  exit 1
fi
echo $$ > "${LOCK_DIR}/pid"
trap 'rm -rf "$LOCK_DIR"' EXIT

# --- 辅助函数：超时执行（进程组隔离，解决子进程孤儿问题） ---
run_with_timeout() {
  local timeout_sec="$1"
  shift
  # 使用 setsid 创建新进程组，超时时 kill 整个进程组（包括子进程）
  # macOS 需要 coreutils 的 gtimeout，Linux 用原生 timeout
  local timeout_cmd="timeout"
  if command -v gtimeout &>/dev/null; then
    timeout_cmd="gtimeout"
  elif ! command -v timeout &>/dev/null; then
    echo "ERROR: 未找到 timeout 或 gtimeout，请安装 coreutils (brew install coreutils)"
    exit 1
  fi
  # --signal=KILL：超时后发送 SIGKILL（不可捕获）
  # --kill-after=10：如果 SIGKILL 后 10 秒仍未退出，再次强杀
  # setsid：创建新会话和进程组，确保子进程树可被整体清理
  setsid "$timeout_cmd" --signal=KILL --kill-after=10 "${timeout_sec}s" "$@"
  local exit_code=$?
  # TODO(预留): 待 claude -p 支持 --output-format json 后，在此提取 cost_usd 写入 .last_step_cost
  return $exit_code
}

# --- 辅助函数：根据 agent 角色确定权限模式 ---
get_permission_mode() {
  local agent_file="$1"
  case "$agent_file" in
    pipeline-designer.md|pipeline-planner.md)
      echo "plan"  # 只读角色：不需要 Bash，使用严格模式
      ;;
    *)
      echo "bypassPermissions"  # Implementer/Fixer 写代码 + Checker/QA 跑测试，都需要 Bash
      ;;
  esac
}

# --- 辅助函数：事后 diff 校验（只读角色不应改动项目代码） ---
verify_no_code_changes() {
  local step_name="$1"
  local agent_file="$2"
  case "$agent_file" in
    pipeline-implementer.md|pipeline-fixer.md)
      return 0  # 写代码角色跳过检查
      ;;
  esac
  # 只读角色：检查是否有 docs/pipeline/ 以外的文件改动
  local unexpected_changes
  unexpected_changes=$(git diff --name-only HEAD 2>/dev/null | grep -v "^docs/pipeline/" || true)
  if [ -n "$unexpected_changes" ]; then
    echo "ERROR: ${step_name}（只读角色）意外修改了项目代码:"
    echo "$unexpected_changes"
    notify_error "Pipeline" "${step_name} 只读角色修改了项目代码，中止"
    exit 1
  fi
}

# --- 辅助函数：执行单步 ---
run_step() {
  local step_name="$1"
  local step_index="$2"
  local agent_file="$3"
  local prompt="$4"
  local expected_output="$5"
  local permission_mode
  permission_mode=$(get_permission_mode "$agent_file")

  update_progress "$step_name" "$step_index" "running"
  echo "=== [${FEATURE}] ${step_name} (permission: ${permission_mode}) ==="

  local exit_code=0
  # 使用 setsid 启动进程组，超时时 kill 整个进程组（解决子进程孤儿问题）
  run_with_timeout ${STEP_TIMEOUT} \
    $CLI_CMD -p "$(cat "${AGENTS_DIR}/${agent_file}")

${prompt}" \
    --permission-mode "${permission_mode}" \
    --max-budget-usd "${STEP_BUDGET}" || exit_code=$?

  if [ $exit_code -ne 0 ]; then
    update_progress "$step_name" "$step_index" "failed"
    notify_error "Pipeline" "${step_name} 执行失败 (exit: ${exit_code})"
    exit 1
  fi

  if [ ! -f "${expected_output}" ]; then
    update_progress "$step_name" "$step_index" "failed"
    notify_error "Pipeline" "${step_name} 未生成输出文件: ${expected_output}"
    exit 1
  fi

  # Handoff 最小结构校验：非空 + 包含必要标题
  if [ ! -s "${expected_output}" ]; then
    update_progress "$step_name" "$step_index" "failed"
    notify_error "Pipeline" "${step_name} 输出文件为空: ${expected_output}"
    exit 1
  fi
  # Handoff 章节标题校验（ERROR 级别，exit 1 强阻断）
  # 核心章节（输入分析/决策/产出）是 Handoff 结构完整性的底线。
  local missing_sections=""
  for section in "输入分析" "决策" "产出"; do
    if ! grep -q "$section" "${expected_output}"; then
      missing_sections="${missing_sections} ${section}"
    fi
  done
  if [ -n "$missing_sections" ]; then
    echo "ERROR: ${step_name} Handoff 缺少核心章节:${missing_sections}"
    notify_error "Pipeline" "${step_name} Handoff 标题缺失强阻断！"
    exit 1
  fi

  # Handoff 结构化验证（ERROR 级别，exit 1 强阻断）
  validate_handoff "$step_name" "${expected_output}"

  # 事后 diff 校验：只读角色不应修改 docs/pipeline/ 以外的文件
  verify_no_code_changes "$step_name" "$agent_file"

  update_progress "$step_name" "$step_index" "completed"
  check_budget
  echo "=== [${FEATURE}] ${step_name} 完成 ==="
}

# --- 辅助函数：解析 REVIEW 行（复用 QA 的鲁棒解析逻辑） ---
# 注：MAX_REVIEW / MAX_CHECK_LOOP 已在顶部配置区定义，此处不重复
parse_review() {
  local review_file="$1"
  local ok_keyword="$2"   # DESIGN_OK 或 PLAN_OK
  local issue_keyword="$3" # DESIGN_ISSUE 或 PLAN_ISSUE
  sed 's/[*_`]//g' "$review_file" | \
    grep -ioE "^[[:space:]]*REVIEW[[:space:]]*:[[:space:]]*(${ok_keyword}|${issue_keyword})" | \
    head -1 | grep -ioE "(${ok_keyword}|${issue_keyword})" || echo "MISSING"
}

# --- 辅助函数：pipeline.sh 独立运行测试判定 PASS/FAIL ---
# 核心原则：PASS/FAIL 判定权在编排器，不在 Subagent。
# Subagent（Checker/QA）负责发现问题并描述问题，pipeline.sh 负责执行测试并判定结果。
# 这杜绝了 LLM "自证清白"（自行 touch 文件）的虚假完成风险。
run_tests() {
  local test_log="${PIPELINE_DIR}/test_output.log"
  local test_exit=0

  # 自动检测项目测试框架并运行
  if [ -f "pytest.ini" ] || [ -f "pyproject.toml" ] || [ -f "setup.cfg" ]; then
    pytest --tb=short 2>&1 | tee "$test_log" || test_exit=$?
  elif [ -f "package.json" ]; then
    npm test 2>&1 | tee "$test_log" || test_exit=$?
  else
    echo "WARNING: 未检测到已知测试框架，跳过独立测试运行" | tee "$test_log"
    test_exit=0
  fi

  return $test_exit
}

parse_result() {
  local test_exit=0
  run_tests || test_exit=$?
  if [ $test_exit -eq 0 ]; then
    echo "PASS"
  else
    echo "FAIL"
  fi
}

# --- 日志文件（per-feature 隔离） ---
LOG_FILE="${PIPELINE_DIR}/pipeline.log"
exec > >(tee -a "${LOG_FILE}") 2>&1
echo "=== Pipeline 启动: ${FEATURE} @ $(date) ==="
echo "=== CLI: ${CLI_CMD} | START_STEP: ${START_STEP:-design} | BUDGET: \$${TOTAL_BUDGET} ==="

# --- START_STEP 断点续传（3 个跨阶段入口） ---
START_STEP="${START_STEP:-design}"

case "$START_STEP" in
  design)
    # 从头开始：检查不应有残留 Handoff（已在前置检查中完成）
    ;;
  implement)
    # 跳过方向决策阶段，直接进入执行
    for f in handoff_clarify.md handoff_design.md handoff_plan.md; do
      if [ ! -f "${PIPELINE_DIR}/${f}" ]; then
        echo "ERROR: 从 implement 恢复需要 ${f}，但文件不存在"
        notify_error "Pipeline" "断点续传缺少前置产物: ${f}"
        exit 1
      fi
    done
    if [ -f "${PIPELINE_DIR}/handoff_run.md" ]; then
      echo "ERROR: handoff_run.md 已存在，请先 pipeline.sh reset ${FEATURE}"
      notify_error "Pipeline" "断点续传: handoff_run.md 已存在"
      exit 1
    fi
    echo "=== [${FEATURE}] 断点续传: 跳过 Design-Plan，从 Implement 开始 ==="
    ;;
  qa)
    # 跳过执行阶段，直接进入验收
    for f in handoff_clarify.md handoff_design.md handoff_plan.md handoff_run.md handoff_check.md; do
      if [ ! -f "${PIPELINE_DIR}/${f}" ]; then
        echo "ERROR: 从 qa 恢复需要 ${f}，但文件不存在"
        notify_error "Pipeline" "断点续传缺少前置产物: ${f}"
        exit 1
      fi
    done
    # 验证 Check 已通过（通过持久化标记文件，而非瞬态的 test_pass_flag）
    if [ ! -f "${PIPELINE_DIR}/.check_passed" ] || [ "$(cat "${PIPELINE_DIR}/.check_passed")" != "PASS" ]; then
      echo "ERROR: Check 通过标记不存在或非 PASS，请先从 implement 阶段恢复"
      notify_error "Pipeline" "断点续传: Check 未通过（.check_passed 标记缺失）"
      exit 1
    fi
    if [ -f "${PIPELINE_DIR}/handoff_qa.md" ]; then
      echo "ERROR: handoff_qa.md 已存在，请先 pipeline.sh reset ${FEATURE}"
      notify_error "Pipeline" "断点续传: handoff_qa.md 已存在"
      exit 1
    fi
    echo "=== [${FEATURE}] 断点续传: 跳过 Design-Plan-Implement-Check，从 QA 开始 ==="
    ;;
  *)
    echo "ERROR: 无效的 START_STEP: ${START_STEP}，可选值: design / implement / qa"
    exit 1
    ;;
esac

# --- 主流程 ---
fix_count=0
step_index=1

if [ "$START_STEP" = "design" ]; then
# ==================== 阶段 1: 方向决策 ====================

# ==================== Design-Plan 评审循环（最多 MAX_REVIEW 轮） ====================
design_review_count=0

run_step "design" $step_index "pipeline-designer.md" \
  "请读取 ${PIPELINE_DIR}/handoff_clarify.md，执行架构设计，输出到 ${PIPELINE_DIR}/handoff_design.md" \
  "${PIPELINE_DIR}/handoff_design.md"

while [ $design_review_count -lt $MAX_REVIEW ]; do
  echo "=== [${FEATURE}] Design 评审（第 $((design_review_count + 1)) 轮） ==="

  # Planner 评审 Design（每轮独立文件，保留评审历史）
  design_review_file="review_design_$((design_review_count + 1)).md"
  run_step "design-review-$((design_review_count + 1))" $step_index "pipeline-planner.md" \
    "请以评审模式运行。读取 ${PIPELINE_DIR}/handoff_design.md 和 ${PIPELINE_DIR}/handoff_clarify.md，评审 Design 文档质量。
评审标准：clarify 规则覆盖、接口完整性、可执行性、过度设计、数据模型。
输出到 ${PIPELINE_DIR}/${design_review_file}
输出格式必须包含判定行：REVIEW: DESIGN_OK 或 REVIEW: DESIGN_ISSUE" \
    "${PIPELINE_DIR}/${design_review_file}"

  # 解析评审结果
  design_verdict=$(parse_review "${PIPELINE_DIR}/${design_review_file}" "DESIGN_OK" "DESIGN_ISSUE")

  case "$(echo "$design_verdict" | tr '[:lower:]' '[:upper:]')" in
    DESIGN_OK)
      echo "=== [${FEATURE}] Design 评审通过 ==="
      notify "Pipeline" "${FEATURE} Design 评审通过，进入 Plan"
      break
      ;;
    DESIGN_ISSUE)
      design_review_count=$((design_review_count + 1))
      if [ $design_review_count -ge $MAX_REVIEW ]; then
        update_progress "design-review" $step_index "failed"
        notify_error "Pipeline" "${FEATURE} Design 经 ${MAX_REVIEW} 轮评审仍有问题"
        echo "ERROR: Design 经 ${MAX_REVIEW} 轮评审仍有问题，退出"
        exit 1
      fi
      echo "=== [${FEATURE}] Design 评审未通过，Designer 修正（第 ${design_review_count} 轮） ==="
      run_step "design-revise-${design_review_count}" $step_index "pipeline-designer.md" \
        "请读取 ${PIPELINE_DIR}/${design_review_file} 中的评审意见和 ${PIPELINE_DIR}/handoff_clarify.md，修正 ${PIPELINE_DIR}/handoff_design.md 中的问题，输出更新后的设计到 ${PIPELINE_DIR}/handoff_design.md" \
        "${PIPELINE_DIR}/handoff_design.md"
      ;;
    *)
      update_progress "design-review" $step_index "failed"
      notify_error "Pipeline" "Design 评审输出缺少 REVIEW 行或格式异常，请检查 ${design_review_file}"
      echo "ERROR: ${design_review_file} 中未找到有效的 REVIEW 行，解析结果: ${design_verdict}"
      exit 1
      ;;
  esac
done

# ⏸️ 可选人工确认（HUMAN_CHECKPOINT，默认开启）
if [ "$HUMAN_CHECKPOINT" = true ]; then
  wait_for_confirmation "design" "${PIPELINE_DIR}/handoff_design.md"
fi

step_index=2

# ==================== Plan-Implement 评审循环（最多 MAX_REVIEW 轮） ====================
plan_review_count=0

run_step "plan" $step_index "pipeline-planner.md" \
  "请读取 ${PIPELINE_DIR}/handoff_clarify.md 和 ${PIPELINE_DIR}/handoff_design.md，编写开发计划，输出到 ${PIPELINE_DIR}/handoff_plan.md" \
  "${PIPELINE_DIR}/handoff_plan.md"

while [ $plan_review_count -lt $MAX_REVIEW ]; do
  echo "=== [${FEATURE}] Plan 评审（第 $((plan_review_count + 1)) 轮） ==="

  # Implementer 评审 Plan（每轮独立文件，保留评审历史）
  plan_review_file="review_plan_$((plan_review_count + 1)).md"
  run_step "plan-review-$((plan_review_count + 1))" $step_index "pipeline-implementer.md" \
    "请以评审模式运行。读取 ${PIPELINE_DIR}/handoff_plan.md 和 ${PIPELINE_DIR}/handoff_design.md，评审 Plan 文档质量。
评审标准：文件路径正确性、AC 可测性、依赖拓扑、任务粒度、设计一致性。
输出到 ${PIPELINE_DIR}/${plan_review_file}
输出格式必须包含判定行：REVIEW: PLAN_OK 或 REVIEW: PLAN_ISSUE" \
    "${PIPELINE_DIR}/${plan_review_file}"

  # 解析评审结果
  plan_verdict=$(parse_review "${PIPELINE_DIR}/${plan_review_file}" "PLAN_OK" "PLAN_ISSUE")

  case "$(echo "$plan_verdict" | tr '[:lower:]' '[:upper:]')" in
    PLAN_OK)
      echo "=== [${FEATURE}] Plan 评审通过 ==="
      notify "Pipeline" "${FEATURE} Plan 评审通过，进入 Implement"
      break
      ;;
    PLAN_ISSUE)
      plan_review_count=$((plan_review_count + 1))
      if [ $plan_review_count -ge $MAX_REVIEW ]; then
        update_progress "plan-review" $step_index "failed"
        notify_error "Pipeline" "${FEATURE} Plan 经 ${MAX_REVIEW} 轮评审仍有问题"
        echo "ERROR: Plan 经 ${MAX_REVIEW} 轮评审仍有问题，退出"
        exit 1
      fi
      echo "=== [${FEATURE}] Plan 评审未通过，Planner 修正（第 ${plan_review_count} 轮） ==="
      run_step "plan-revise-${plan_review_count}" $step_index "pipeline-planner.md" \
        "请读取 ${PIPELINE_DIR}/${plan_review_file} 中的评审意见和 ${PIPELINE_DIR}/handoff_design.md，修正 ${PIPELINE_DIR}/handoff_plan.md 中的问题，输出更新后的计划到 ${PIPELINE_DIR}/handoff_plan.md" \
        "${PIPELINE_DIR}/handoff_plan.md"
      ;;
    *)
      update_progress "plan-review" $step_index "failed"
      notify_error "Pipeline" "Plan 评审输出缺少 REVIEW 行或格式异常，请检查 ${plan_review_file}"
      echo "ERROR: ${plan_review_file} 中未找到有效的 REVIEW 行，解析结果: ${plan_verdict}"
      exit 1
      ;;
  esac
done

# ⏸️ 可选人工确认（HUMAN_CHECKPOINT，默认开启）
if [ "$HUMAN_CHECKPOINT" = true ]; then
  wait_for_confirmation "plan" "${PIPELINE_DIR}/handoff_plan.md"
fi

fi  # END: if [ "$START_STEP" = "design" ]

# ==================== 阶段 2: 执行交付 ====================

if [ "$START_STEP" = "design" ] || [ "$START_STEP" = "implement" ]; then

step_index=3

# ==================== Implement-Check 循环（最多 MAX_CHECK_LOOP 轮） ====================
check_loop_count=0

# P0-5: Implement 回滚锚点——记录执行前的 git HEAD
IMPL_BASE=$(git rev-parse HEAD 2>/dev/null || echo "NO_GIT")
echo "=== [${FEATURE}] Implement 回滚锚点: ${IMPL_BASE} ==="

run_step "implement" $step_index "pipeline-implementer.md" \
  "请读取 ${PIPELINE_DIR}/handoff_plan.md 和 ${PIPELINE_DIR}/handoff_design.md，执行开发，输出到 ${PIPELINE_DIR}/handoff_run.md" \
  "${PIPELINE_DIR}/handoff_run.md"

while true; do
  step_index=4
  run_step "check" $step_index "pipeline-checker.md" \
    "请读取 ${PIPELINE_DIR}/handoff_plan.md 和 ${PIPELINE_DIR}/handoff_run.md，执行代码检查（五维：测试/Lint/类型/代码质量/AC覆盖），输出到 ${PIPELINE_DIR}/handoff_check.md。
注意：你只负责检查并描述发现的问题，PASS/FAIL 判定由编排脚本独立运行测试决定，你无权判定。" \
    "${PIPELINE_DIR}/handoff_check.md"

  # pipeline.sh 独立运行测试判定 PASS/FAIL（不依赖 Subagent 产物）
  check_result=$(parse_result)

  case "$(echo "$check_result" | tr '[:lower:]' '[:upper:]')" in
    PASS)
      echo "=== [${FEATURE}] Check 通过，进入 QA ==="
      # 写入持久化标记，供 START_STEP=qa 断点续传时验证 Check 已通过
      echo "PASS" > "${PIPELINE_DIR}/.check_passed"
      break
      ;;
    FAIL)
      check_loop_count=$((check_loop_count + 1))
      if [ $check_loop_count -ge $MAX_CHECK_LOOP ]; then
        update_progress "check" $step_index "failed"
        notify_error "Pipeline" "${FEATURE} 代码检查 ${MAX_CHECK_LOOP} 轮未通过"
        echo "ERROR: 代码检查 ${MAX_CHECK_LOOP} 轮未通过，退出"
        exit 1
      fi
      echo "=== [${FEATURE}] Check FAIL，开始第 ${check_loop_count} 次 QA 前修复 ==="
      run_step "fix-pre-${check_loop_count}" $step_index "pipeline-fixer.md" \
        "请读取 ${PIPELINE_DIR}/handoff_check.md 和 ${PIPELINE_DIR}/handoff_plan.md，修复 Check 发现的问题，输出到 ${PIPELINE_DIR}/handoff_fix_pre_${check_loop_count}.md" \
        "${PIPELINE_DIR}/handoff_fix_pre_${check_loop_count}.md"
      ;;
    *)
      # 防御性分支：parse_result() 正常只返回 PASS/FAIL，此分支理论上不可达
      update_progress "check" $step_index "failed"
      notify_error "Pipeline" "Check 结果解析异常（测试框架运行异常），请检查 handoff_check.md"
      echo "ERROR: parse_result 返回异常值: ${check_result}（期望 PASS 或 FAIL）"
      exit 1
      ;;
  esac
done

fi  # END: if [ "$START_STEP" = "design" ] || [ "$START_STEP" = "implement" ]

# ==================== 阶段 3: 验收修复 ====================

step_index=5

# ==================== QA-Fix 循环 ====================
# --- QA/Fix 循环 ---
while true; do
  update_progress "qa" 5 "running"
  echo "=== [${FEATURE}] QA (第 $((fix_count + 1)) 轮) ==="

  qa_exit=0
  qa_permission=$(get_permission_mode "pipeline-qa.md")
  run_with_timeout ${STEP_TIMEOUT} \
    $CLI_CMD -p "$(cat "${AGENTS_DIR}/pipeline-qa.md")

请读取 ${PIPELINE_DIR}/handoff_clarify.md（验收标准）和 ${PIPELINE_DIR}/handoff_design.md（接口契约），执行验收测试，输出到 ${PIPELINE_DIR}/handoff_qa.md。
注意：你只负责逐条验收并描述发现的问题（期望行为/实际行为/复现命令），PASS/FAIL 判定由编排脚本独立运行测试决定，你无权判定。" \
    --permission-mode "${qa_permission}" \
    --max-budget-usd "${STEP_BUDGET}" || qa_exit=$?

  if [ $qa_exit -ne 0 ]; then
    update_progress "qa" 5 "failed"
    notify_error "Pipeline" "QA 执行失败 (exit: ${qa_exit})"
    exit 1
  fi

  if [ ! -f "${PIPELINE_DIR}/handoff_qa.md" ]; then
    update_progress "qa" 5 "failed"
    notify_error "Pipeline" "QA 未生成输出文件"
    exit 1
  fi

  # 非空检查（与 run_step 一致）
  if [ ! -s "${PIPELINE_DIR}/handoff_qa.md" ]; then
    update_progress "qa" 5 "failed"
    notify_error "Pipeline" "QA 输出文件为空: handoff_qa.md"
    exit 1
  fi
  # Handoff 章节标题检查（与 run_step 一致）
  qa_missing_sections=""
  for section in "输入分析" "决策" "产出"; do
    if ! grep -q "$section" "${PIPELINE_DIR}/handoff_qa.md"; then
      qa_missing_sections="${qa_missing_sections} ${section}"
    fi
  done
  if [ -n "$qa_missing_sections" ]; then
    echo "ERROR: QA Handoff 缺少核心章节:${qa_missing_sections}"
    notify_error "Pipeline" "QA Handoff 标题缺失强阻断！"
    exit 1
  fi

  # QA 是只读角色（虽然需要 Bash 跑测试），检查是否意外修改了项目代码
  verify_no_code_changes "qa" "pipeline-qa.md"
  check_budget

  # pipeline.sh 独立运行测试判定 PASS/FAIL
  # 区分 INFRA_ERROR（服务启动失败/端口占用/依赖缺失）和功能 FAIL
  result=$(parse_result)
  # 检查是否为基础设施错误（测试框架本身无法运行，区别于功能测试失败）
  if grep -qi "INFRA_ERROR\|服务启动失败\|端口占用\|ConnectionRefused" "${PIPELINE_DIR}/test_output.log" 2>/dev/null; then
    update_progress "qa" 5 "infra-error"
    notify_error "Pipeline" "QA 基础设施错误（非功能缺陷），请检查服务配置"
    echo "ERROR: QA 阶段检测到基础设施错误（服务启动失败/端口占用等），不进入 Fix 循环"
    exit 1
  fi

  case "$(echo "$result" | tr '[:lower:]' '[:upper:]')" in
    PASS)
      update_progress "done" 6 "completed"
      notify "Pipeline" "${FEATURE} QA 验收通过，请查看结果"
      echo "=== [${FEATURE}] QA PASS ==="
      exit 0
      ;;
    FAIL)
      # 继续进入 fix 循环
      ;;
    *)
      # 防御性分支：parse_result() 正常只返回 PASS/FAIL，此分支理论上不可达
      update_progress "qa" 5 "failed"
      notify_error "Pipeline" "QA 结果解析异常（测试框架运行异常），请检查 handoff_qa.md"
      echo "ERROR: parse_result 返回异常值: ${result}（期望 PASS 或 FAIL）"
      exit 1
      ;;
  esac

  # RESULT: FAIL → 进入 Fix 循环
  fix_count=$((fix_count + 1))
  if [ $fix_count -ge $MAX_FIX ]; then
    update_progress "qa-failed" 5 "failed"
    notify_error "Pipeline" "${FEATURE} 修复已达 ${MAX_FIX} 次，请人工排查"
    echo "ERROR: 修复次数超过 ${MAX_FIX}，退出"
    exit 1
  fi

  # 升级策略：第 5 次修复仍然 FAIL，暂停通知人工介入
  if [ $fix_count -ge 5 ]; then
    notify_error "Pipeline" "${FEATURE} 已修复 ${fix_count} 次仍 FAIL，建议人工排查"
    wait_for_confirmation "fix-escalation" "${PIPELINE_DIR}/handoff_qa.md"
  fi

  echo "=== [${FEATURE}] QA FAIL，开始第 ${fix_count} 次修复 ==="

  # 构建历史修复上下文（第 3 次起注入，避免重复方案）
  fix_history=""
  if [ $fix_count -ge 3 ]; then
    for i in $(seq 1 $((fix_count - 1))); do
      if [ -f "${PIPELINE_DIR}/handoff_fix_${i}.md" ]; then
        fix_history="${fix_history}
--- 第 ${i} 次修复记录（失败） ---
$(head -50 "${PIPELINE_DIR}/handoff_fix_${i}.md")
"
      fi
    done
  fi

  fix_prompt="请读取 ${PIPELINE_DIR}/handoff_qa.md 和 ${PIPELINE_DIR}/handoff_check.md，修复问题，输出到 ${PIPELINE_DIR}/handoff_fix_${fix_count}.md"
  if [ -n "$fix_history" ]; then
    fix_prompt="${fix_prompt}

注意：以下是之前的修复尝试记录（均失败），请分析为什么之前的方案没有生效，使用不同的方法：
${fix_history}"
  fi

  run_step "fix-${fix_count}" 5 "pipeline-fixer.md" \
    "$fix_prompt" \
    "${PIPELINE_DIR}/handoff_fix_${fix_count}.md"

  run_step "re-check-${fix_count}" 5 "pipeline-checker.md" \
    "请读取 ${PIPELINE_DIR}/handoff_plan.md 和 ${PIPELINE_DIR}/handoff_fix_${fix_count}.md，重新执行代码检查，输出到 ${PIPELINE_DIR}/handoff_check.md" \
    "${PIPELINE_DIR}/handoff_check.md"
done
```

### 3.4 关键设计决策

| 决策 | 理由 |
|------|------|
| **(P0 新增) 交互式 Design/Plan 确认点** | Design/Plan 是方向性决策。不再是简单的 Yes/No，而是支持 `pipeline.sh review` 进入上下文对话修正文档。 |
| **(P0 新增) Subagent 输出前自检** | 参考 Gemini 提示词指南「自我批判」原则，每个 Subagent Prompt 末尾增加自检清单，LLM 输出前逐条对照检查。 |
| **(P1 新增) Handoff 结构化验证** | 升级单纯的 `grep` 关键词匹配。要求 Subagent 将关键元数据（如状态、风险等级）包裹在 XML 标签中（如 `<metadata>...</metadata>`），实现更鲁棒的提取。 |
| **(P1 新增) Fix 历史注入 + 升级策略** | ≥ 3 次修复时注入前几次失败记录，避免重复方案；≥ 5 次修复时暂停通知人工介入，不再盲目重试。 |
| **(P0 vFinal) 判定权分离** | PASS/FAIL 判定权在 pipeline.sh，不在 Subagent。pipeline.sh 在每个 Check/QA 步骤后独立运行项目测试套件（pytest/npm test），根据退出码判定。Subagent 只负责发现问题并描述，无权判定 PASS/FAIL，杜绝"自证清白"的虚假完成。 |
| **(P0 新增) 阻断性降级约束** | 对待任何环节的 Handoff 文档核心内容缺失问题，一律实施 `exit 1` 强杀中断管线，绝对不再通过 `Warning` 发出带病同行的宽松信号。 |
| **(P0 新增) 全进程树防瘫痪机制** | 调用 GNU 系统级别 `timeout` 参数并在超时时挂载 `KILL` 强制信号，用来平替早先具有僵尸死锁隐患的 `perl alarm` 单管进程杀手。 |
| **(P0 升级) 费用总控（数据驱动）** | `STEP_BUDGET`（$10）和 `TOTAL_BUDGET`（$200）为**临时占位值**，必须在正式使用前通过 3 次不同规模需求的实测校准。实测方式：跑完 Pipeline 后查 Anthropic Dashboard 实际费用，用 P90 × 1.5 设定 TOTAL_BUDGET，P90 × 2 设定 STEP_BUDGET。当前 `claude -p` 不输出 session cost，暂用步数 × `STEP_BUDGET` 估算 |
| **(P0 新增) 对抗性思维（Checker/QA 专属）** | 对抗性审查仅适用于 Checker 和 QA（它们审查的是代码产物，有客观标准）。Design-Plan / Plan-Implement 评审循环定位为**结构化 checklist 校验**（检查覆盖率、格式、可执行性），而非对抗性质量审查——同一模型的两次调用不构成真正的对抗。 |
| **(P0 新增) 交互式验收 (Interactive Sign-off)** | Design 阶段额外生成 `Key_Decisions.md`，汇总关键决策点（如技术选型、架构变更），让用户只需 Review 决策而非整篇文档。 |
| **(P0 新增) SOP 化 Prompt (CoT + Checklist)** | 强制所有 Agent 输出思维链 (`<thinking>`)，并在末尾执行自我修正检查清单 (`Self-Correction Checklist`)，不通过则重写。 |
| **(P0 新增) 早期熔断 (Fail Fast)** | 下游（如 Planner）发现上游（Design）重大缺陷时，有权拒绝执行并直接报错终止 Pipeline，而不是试图"填坑"。 |
| **(P0 新增) 断点续传** | 支持 `START_STEP` 环境变量，3 个跨阶段入口（design/implement/qa），每个入口验证前置产物完整性。解决长流程中间失败需重跑的痛点 |
| **(新增) 评审循环先执行再审查** | Designer 先输出完整设计，Planner 再审查。不是 Planner 先提要求 Designer 再写。保证每轮都有完整可审的产出物 |
| **(新增) 评审输出独立文件** | 评审反馈作为独立文件（review_design_N.md / review_plan_N.md，N = 轮次编号），被评审方修正时可同时读取原需求和评审意见。比 bash 变量注入更稳健 |
| Check/QA PASS/FAIL 判定 | pipeline.sh 独立运行 `pytest`/`npm test`，退出码 0 = PASS，非 0 = FAIL。Subagent 无权判定，只负责描述发现的问题 |
| Implement-Check 循环上限 3 轮 | Check 阶段问题是代码层面的，修复收敛快；3 轮已足够。QA 阶段是功能层面，上限 10 轮 |
| QA 结果解析 | pipeline.sh 独立运行测试套件，退出码确定性判定（与 Check 共用 `parse_result()` 逻辑） |
| 每步独立 `claude -p` | 独立上下文窗口，步骤间通过 Handoff 文件传递信息 |
| `$CLI_CMD` 环境变量 | 一行配置切换 claude/claude-codex/claude-gemini，无缝支持多 backend |
| `PROJECT_DIR` 参数 | 确保 Handoff 文件落在正确的项目目录下，而非 pipeline.sh 所在目录 |
| `.pipeline-progress-{feature}.json` | 进度文件按 feature 隔离，供 Status Line 被动读取，零 token 开销 |
| 锁目录防并行 | `mkdir` 原子操作创建锁目录，解决并发竞态。同一 feature 不允许两个 Pipeline 同时运行，不同 feature 互不影响 |
| `set -euo pipefail` | 任何命令失败立即退出，不静默继续 |
| `trap 'rm -rf "$LOCK_DIR"' EXIT` | 无论正常退出还是异常退出，都清理锁目录 |
| `run_with_timeout` + `setsid` | 使用 `setsid` 创建新进程组 + `timeout --signal=KILL` 硬超时（默认 1800 秒），彻底解决子进程孤儿问题（macOS 用 `gtimeout`） |
| `|| exit_code=$?` 捕获退出码 | 绕过 `set -e` 的立即退出行为，确保失败时能更新进度文件和发送通知 |
| 进度文件按 feature 隔离 | `.pipeline-progress-{feature}.json`，多个 Pipeline 并行时互不覆盖 |
| 启动前检查残留 Handoff 文件 | 防止上次 Pipeline 未清理的文件被误读，确保每次从干净状态开始 |
| 自动模式权限按角色分级 | `--permission-mode` 按角色区分：Designer/Planner 使用 `plan`（不需要 Bash），其余角色（Implementer/Fixer/Checker/QA）使用 `bypassPermissions`（需要 Bash 跑测试或写代码）。事后 `git diff` 校验只读角色（Designer/Planner/Checker/QA）是否意外修改 `docs/pipeline/` 以外的文件 |
| feature name 合法性校验 | 只允许中文、英文、数字、下划线、连字符。防止空格和特殊字符导致路径拼接异常或注入 |
| 进度文件原子写入 | 先写临时文件（`.tmp.$$`）再 `mv`，防止 Status Line 读取到半写入的 JSON |
| Handoff 最小结构校验 | 检查输出文件非空且包含「输入分析/决策/产出」关键标题，拦截空文件或格式严重偏离的输出 |
| **(新增) jq 依赖检查** | Status Line 依赖 `jq` 解析 JSON。启动前检查 `jq` 是否安装，未安装给出警告，避免 Status Line 静默失效。 |

### 3.5 异常处理

| 异常类型 | 检测方式 | 处理 |
|---------|---------|------|
| `handoff_clarify.md` 不存在 | `[ ! -f handoff_clarify.md ]` | 发送系统通知，脚本退出（提示先执行 /clarify） |
| `claude -p` 执行失败 | `|| exit_code=$?` 捕获退出码 | 更新进度为 failed，发送系统通知，脚本退出 |
| Handoff 文件未生成 | `[ ! -f expected_output ]` | 发送系统通知，脚本退出 |
| QA 反复失败 | `fix_count >= MAX_FIX` | 发送系统通知，脚本退出 |
| 同一 feature 重复启动 | 锁文件存在检查 | 拒绝启动，发送通知 |
| 脚本被 kill | `trap EXIT` | 清理锁文件 |
| 单步超时（CLI 挂死） | `run_with_timeout` + `setsid` 进程组隔离，`timeout --signal=KILL` 触发（exit code 137） | 更新进度为 failed，发送通知，脚本退出 |
| QA 后测试套件未通过 | pipeline.sh 独立运行 `pytest`/`npm test`，退出码非 0 | 视为 FAIL，进入 fix 循环 |
| 残留 Handoff 文件 | 启动时逐文件检查（含 handoff_fix_*.md） | 拒绝启动，发送通知，要求用户清理 |
| feature name 非法字符 | 正则校验（启动时） | 拒绝启动，提示合法字符集 |
| Handoff 文件为空 | `[ ! -s expected_output ]` | 更新进度为 failed，发送通知，脚本退出 |
| Handoff 章节标题缺失 | `grep` 检查「输入分析/决策/产出」标题 | ERROR 级别：`exit 1` 强阻断 + 通知 |
| **(新增) Handoff 结构验证失败** | `validate_handoff` 按步骤 grep 检查 | ERROR 级别：`exit 1` 强阻断 + 通知 |
| **(新增) 只读角色修改项目代码** | `verify_no_code_changes` 事后 `git diff` 校验 | ERROR 级别：`exit 1` 强阻断 + 通知 |
| **无效起始步骤** | 校验 `START_STEP` 参数 | 报错退出，列出可选步骤 |
| **断点续传缺少前置产物** | 检查 `handoff_*.md` 是否存在 | 报错退出，提示缺少特定文件 |
| **(新增) 人工确认超时** | confirm 文件 24h 内未出现 | 更新进度为 confirmation-timeout，发送通知，脚本退出 |
| **(新增) 人工确认被拒绝** | confirm 文件内容以 `REJECT` 开头 | 更新进度为 rejected，发送通知，脚本退出 |
| **(新增) 累计费用超预算** | `TOTAL_COST > TOTAL_BUDGET`（当前为步数 × STEP_BUDGET 估算，待 claude -p 支持 cost 输出后升级为实际费用） | 暂停等待人工确认继续或终止 |
| **(新增) Fix 升级人工** | `fix_count >= 5` 且仍 FAIL | 暂停等待人工确认继续或终止 |
| **(新增) Implement 中途失败** | implement 步骤退出码非 0 或 handoff_run.md 未生成 | 通知用户"Implement 阶段产生了 N 个 commit（hash 列表），请自行决定是否保留"，pipeline.sh 不做自动回滚 |
| **(新增) 用户重跑同一 Feature** | 用户调用 `pipeline.sh reset {feature}` | 删除除 handoff_clarify.md 外的所有 Handoff 文件 + 进度文件 + 锁文件，保留 clarify 文档以便直接重跑 |
| **(新增) Design 评审循环耗尽** | `design_review_count >= MAX_REVIEW` | 通知用户"Design 经 3 轮评审仍有问题"，退出 |
| **(新增) Plan 评审循环耗尽** | `plan_review_count >= MAX_REVIEW` | 通知用户"Plan 经 3 轮评审仍有问题"，退出 |
| **(新增) Check 循环耗尽（QA 前）** | `check_loop_count >= MAX_CHECK_LOOP` | 通知用户"代码检查 3 轮未通过"，退出 |
| **(新增) 评审输出无有效 REVIEW 行** | `parse_review` 解析结果为 MISSING | 通知用户，退出（不重试） |
| **(新增) Check/QA 结果解析异常** | 测试框架未检测到或运行异常（如 pytest 未安装、配置文件损坏） | 通知用户，退出（防御性分支，正常流程不会触发） |

**所有异常都通过系统通知（macOS `osascript` / Linux `notify-send`）告知用户**，确保后台运行时用户不会错过。

---

## 4. 步骤质量设计

> **这是整个方案最核心的部分。** 每个环节的 Subagent 质量直接决定全流程的天花板。如果某个环节质量差，会拉垮后续所有环节。

### 4.0 Subagent Prompt 设计原则（通用）

> 以下原则适用于所有 6 个 Subagent，是 prompt 编写时必须遵循的共性要求。

#### 原则 1：角色身份定义

每个 Subagent 的 prompt 开头必须定义明确的角色身份，而非仅描述职责。角色身份影响 LLM 的行为倾向——"你是独立的代码审计员"比"你负责检查代码"能产出更严格的审查。

Pipeline 本质上是用 Subagent 替代真实软件交付团队中的每个角色。质量来自角色间的**张力**——架构师画线开发者不能越线、审查者的目标是找问题而非证明没问题、QA 不信任上游任何自证。因此角色定义必须包含三要素：身份（你是谁）、行为准则（你怎么做）、边界（你不做什么）。

| Subagent | 替代真人 | 角色身份 | 行为准则 | 不做什么（负向约束） |
|----------|---------|---------|---------|-------------------|
| Designer | 架构师 | 资深架构师，熟悉本项目代码风格和技术栈 | 先扫描现有代码再设计；拒绝需求文档未提及的功能；关键决策必须多方案对比 | 不写代码、不做任务拆分（那是 Planner 的事） |
| Planner | 技术 PM | 技术项目经理，能读代码来判断任务粒度 | 每个任务可在一次 commit 完成；每个 AC 可翻译成 assert；标注文件路径和依赖 | 不修改设计决策、不写实现代码 |
| Implementer | 开发工程师 | 严格遵循 TDD 的开发工程师 | 先写测试确认失败，再写实现确认通过；一任务一 commit；遇阻标注 BLOCKED | 不改设计接口、不跳过失败测试、不删除已有测试 |
| Checker | 对抗性审查者 | **红蓝对抗中的攻击方**，以"找茬"为乐的资深黑客 | 必须假设代码有漏洞；使用静态分析 + 逻辑推演寻找边界条件；不仅看 Lint，更看逻辑漏洞 | 不做"橡皮图章"式通过、不接受"看起来没问题"的模糊结论、不替开发者辩护 |
| QA | QA 工程师 | 产品质量守门人，不信任上游任何自证 | 只以 clarify 文档为验收标准；独立执行端到端验证；开发说通过的，自己再验一遍 | 不修改代码、不看代码质量（那是 Checker 的事）、不重复跑 lint/测试 |
| Fixer | 值班修复工程师 | 当值修复工程师，限时限范围 | 先根因分析再动手；每次修复附回归测试；修复前后 diff 测试结果 | 不顺手重构、不添加新功能、不通过删除测试或降低标准来"修复" |

**人的角色**：用户在 `/clarify`（需求定义）和 `/ship`（最终验收）环节亲自参与，pipeline.sh 中间环节自动运行。人 = 产品负责人，负责首尾决策；Subagent = 执行团队，负责中间交付。

#### 原则 2：显式推理过程

Subagent 的输出必须包含推理过程段落，而非直接给出结论。没有推理过程，质量门控中的检查项（如"是否扫描了现有代码"）就变成不可验证的声明。

每个 Subagent 的 Handoff 文档必须包含：
1. **"我看到了什么"**（输入分析）：读取了哪些文件、发现了什么
2. **"我决定做什么"**（决策及理由）：为什么选择方案 A 而非方案 B
3. **"我产出了什么"**（核心输出）：具体的设计/计划/代码/报告

#### 原则 3：Few-shot 对比示例

每个 Subagent 的 prompt 中必须包含 1-2 组"好输出 vs 坏输出"对比示例。LLM 从具体示例中学习模式的能力远强于从抽象描述中理解意图。

示例格式：
```
### ✅ 好的输出
[具体的、可操作的、有客观证据的内容]

### ❌ 坏的输出
[泛泛的、主观的、不可验证的内容]
```

每个 Subagent 的具体示例见 4.1-4.6 各节。

#### 原则 4：结构化交接项

Handoff 文档通用格式中的"下一步需要关注的点"必须替换为针对每个步骤的**固定传递项清单**，避免自由文本导致关键信息丢失。

| 步骤 | 向下游传递的固定项 |
|------|------------------|
| Design → Plan（评审） | **评审反馈文件路径（review_design_N.md）**，用于 Designer 修正 |
| Design → Plan | 接口清单、模块依赖图、技术风险点、设计约束 |
| Plan → Implement（评审） | **评审反馈文件路径（review_plan_N.md）**，用于 Planner 修正 |
| Plan → Implement | 任务执行顺序、文件改动清单、每任务 AC、测试策略 |
| Implement → Check | commit 列表（含 hash）、测试运行结果摘要、已知遗留问题、BLOCKED 任务。commit_hashes 同时用于 Implement 失败时通知用户可回滚的 commit 范围 |
| Check → QA | QA 不直接读取 Check 输出，保证独立性。pipeline.sh 在 QA prompt 中可选注入 Checker 已发现的 FAIL 项摘要（仅供参考） |
| QA → Fix | FAIL 项清单（含期望行为 + 实际行为 + 复现命令） |
| Fix → Check | 修复内容摘要、回归测试清单、修复前后测试 diff |

#### 原则 5：理解输入 + 验证输出

> **核心问题**：现有设计中，每个阶段的门控只检查"文件是否存在"（`ls docs/需求澄清/clarify_*.md`），不检查"是否理解了文件内容"。文件存在 ≠ 理解内容。这导致各阶段在不理解上游产出的情况下开始执行，产出质量不可控。

每个 Subagent 在执行前必须**理解输入**（不只是检查文件存在），在完成前必须**验证输出**（不只是检查格式正确）。

**理解输入**：

| 阶段 | 仅检查文件存在（❌ 不够） | 理解输入内容（✅ 必须） |
|------|------------------------|----------------------|
| Design | clarify 文档存在 | 逐条理解每个规则的业务行为、正例的数据流、反例的校验逻辑，从规则推导出模块/接口方向 |
| Plan | design + clarify 文档存在 | 理解接口间的依赖关系、数据流向，从依赖关系推导任务拆分和执行顺序 |
| Run-Plan | plan 文档存在 | 理解每个任务的 AC 和文件边界，从 AC 推导测试用例 |
| Check | run + plan 文档存在 | 理解预期行为（AC）和实际实现，从 AC 推导检查标准 |
| QA | clarify 文档存在 | 回到需求源头，理解每条规则的正例/反例，从示例推导验收场景 |

**验证输出**：

| 阶段 | 仅检查格式正确（❌ 不够） | 验证输出内容（✅ 必须） |
|------|------------------------|----------------------|
| Design | 有接口定义、有数据模型 | 每条 clarify 规则都有对应的接口或数据模型支撑，无遗漏 |
| Plan | 有任务清单、有依赖关系 | 任务覆盖所有设计接口，AC 可追溯到 clarify 规则 |
| Run-Plan | 代码写好了、测试通过了 | 每个任务的 AC 都有对应测试且通过 |
| Check | 五维检查都做了 | 检查结果可追溯到具体的 AC 和代码行 |
| QA | 逐条验收了 | 验收场景覆盖 clarify 的正例、反例、边界 |

**与原则 2（显式推理过程）的关系**："理解输入"体现在 Handoff 的"我看到了什么"部分——不只是列出读了哪些文件，而是说明从中理解到了什么、推导出了什么方向。"验证输出"体现在完成前的自检——对照上游规则逐条确认覆盖。

#### 原则 6：SOP 化 Prompt (CoT + Self-Correction)

参考《Gemini 提示词实践指南》，每个 Subagent 必须遵循"Thinking Process"和"Constraint Placement"原则：

1.  **强制思维链 (Chain of Thought)**：在输出最终 Markdown 块之前，必须先输出 `<thinking>` 标签，显式展示：
    *   **Decompose**: 拆解任务
    *   **Analyze**: 分析输入
    *   **Synthesize**: 综合决策
    *   **Reflect**: 反思潜在问题

2.  **自我修正检查清单 (Self-Correction Checklist)**：在 Prompt **最末尾**（指令后置）加入强制检查项。如果检查不通过，必须自我修正，禁止输出。
    ```markdown
    Before outputting the final Markdown block, you MUST verify:
    - [ ] Have I handled all edge cases mentioned in the input?
    - [ ] Is my tone objective and professional?
    - [ ] Did I verify my output format against requirements?
    ```

#### 原则 7：早期熔断 (Fail Fast)

**核心理念**：与其让下游 Agent 试图修复上游的根本性错误（"填坑"），不如直接报错熔断，让人介入。

*   **Planner** 发现 **Design** 缺失关键接口定义 → `EXIT(CRITICAL_DESIGN_FLAW)`
*   **Implementer** 发现 **Plan** 任务逻辑矛盾 → `EXIT(INVALID_PLAN)`
*   **Checker** 发现 **Code** 完全不可运行 → `EXIT(BROKEN_CODE)`

Prompt 中必须明确赋予 Agent "拒绝执行" 的权利。

#### 原则 8：对抗性思维 (Adversarial Mindset)

**核心理念**：对于 Checker 和 QA，必须采用"有罪推定"，不仅仅是检查者，更是攻击者。
*   **Checker**: "你是一个受雇寻找漏洞的外部安全审计员。如果你放过了糟糕的代码，你将失去执照。必须假设代码有漏洞，你的任务是找到它。"
*   **QA**: "假设开发在骗你，你的任务是证明功能是坏的。不要相信任何'自测通过'的鬼话。"

#### 原则 9：负向约束 (Negative Constraints)

**核心理念**：LLM 常常因为"太想帮忙"而画蛇添足。必须明确定义**不做什么**。
*   **Do NOT**: 重构与任务无关的代码。
*   **Do NOT**: 添加"未来可能用到"的配置或依赖。
*   **Do NOT**: 删除现有的测试用例。
*   **Do NOT**: 试图修复上游设计的缺陷（那是 Designer 的事，直接报错）。

#### 原则 10：自动化友好的结构化输出 (Structured Output)

**核心理念**：为了让 `pipeline.sh` 能可靠地解析状态，关键元数据必须包裹在 XML 标签中。
*   **Metadata**: `<metadata>{"status": "PASS", "risk": "low"}</metadata>`
*   **Summary**: `<summary>...</summary>`
*   **Critical Decision**: `<critical_decision>...</critical_decision>`

---

### 4.1 Design（架构设计）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-designer.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `architecture`
**Skill 入口**: `/design`（`context: fork`, `agent: pipeline-designer`）
**工具**: Read, Write, Glob, Grep, WebSearch
**输入**: `handoff_clarify.md`
**输出**: `handoff_design.md`

#### 常见失败模式（为什么质量差）

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **不看现有代码** | 凭空设计，忽略项目已有的模式和约定 | 实现时发现与现有代码冲突，大量返工 |
| **只有正常路径** | 接口只定义成功场景，无错误处理 | 开发者自行决定错误处理，质量不可控 |
| **过度设计** | 引入不必要的抽象层、设计模式、中间件 | 增加实现复杂度，偏离需求 |
| **照搬模板** | 输出看起来完整但全是泛泛的描述 | Plan 无法基于此产出可执行的任务 |

#### 质量标准（什么是好的输出）
<!-- → 提取到 Skill: architecture -->

- **必须先扫描现有代码**：用 Glob/Grep 了解项目结构、现有模式、技术栈实际用法，设计必须与现有代码风格一致
- **接口定义完整**：每个接口包含入参（类型+校验规则）、出参（成功+失败）、错误码、错误场景
- **模块边界清晰**：每个模块说明"负责什么"和"不负责什么"
- **设计可追溯到需求**：每个设计决策能对应到需求文档中的具体功能点

#### 理解输入 + 验证输出（原则 5 的具体应用）

**理解输入**：Designer 在开始设计前，必须逐条理解 clarify 文档中的规则和示例：
- 对每条规则：理解其业务行为含义
- 对每个正例：推导出需要什么接口、什么数据流来支撑这个场景
- 对每个反例：推导出需要什么校验逻辑来阻止这个场景
- 对排除项：明确哪些不设计
- **从规则推导设计方向**：规则 → 需要哪些模块/接口，而非凭空架构

```
### ✅ 好的理解输入
读取 handoff_clarify.md：
- 规则 1"用户注册"：正例要求返回 201 + 用户信息 → 需要 POST /api/users 接口 + User 模型
  反例要求重复用户名返回 409 → User 模型需要 username 唯一约束
- 规则 2"密码校验"：正例要求 8 位以上通过 → 模型层 validate_password
  反例要求 7 位拒绝返回 422 → 需要明确错误码和错误消息格式
→ 设计方向：2 个接口（注册+登录），1 个模型（User），校验逻辑放模型层

### ❌ 坏的理解输入
读取了 handoff_clarify.md，共 3 条规则。
（只列出数量，没有理解内容，没有推导设计方向）
```

**验证输出**：Designer 在输出 Handoff 前，必须验证设计覆盖了所有 clarify 规则：

| clarify 规则 | 对应的设计产出 | 覆盖状态 |
|-------------|--------------|---------|
| 规则 1: 用户注册 | POST /api/users + User 模型 | ✅ 覆盖 |
| 规则 2: 密码校验 | User.validate_password() | ✅ 覆盖 |
| 排除项: 不含邮箱验证 | 设计中未包含邮箱验证接口 | ✅ 符合 |

如有规则无对应设计产出 → 设计不完整，不能输出。

#### 多方案对比（Tree of Thoughts）
<!-- → 提取到 Skill: architecture -->

Designer 在做关键架构决策时，必须列出 2-3 个备选方案并对比，而非直接给出"唯一正确答案"。对比维度至少包含：实现复杂度、与现有代码的一致性、可维护性。

```
### 路由方案对比

| 维度 | 方案 A: 文件路由 | 方案 B: 集中路由 | 方案 C: 装饰器路由 |
|------|----------------|----------------|------------------|
| 与现有代码一致性 | ✅ 项目已用此模式 | ❌ 需改造现有路由 | ❌ 需引入新依赖 |
| 实现复杂度 | 低 | 中 | 中 |
| 可维护性 | 中（文件多） | 高（集中管理） | 高（声明式） |

**选择**: 方案 A，理由：与现有 12 个路由文件风格一致，避免两套模式并存。
```

#### Few-shot 示例
<!-- → 提取到 Skill: architecture -->

```
### ✅ 好的设计输出
## 输入分析（我看到了什么）
扫描项目结构发现：
- 现有用户模型在 src/models/user.py（SQLAlchemy ORM，已有 20+ 字段）
- 认证逻辑在 src/auth/jwt_handler.py（JWT + Redis 黑名单）
- API 风格：RESTful，统一用 src/api/v1/ 下按资源分文件
- 现有路由用文件路由模式，已有 12 个路由文件

## 决策及理由（我决定做什么）
- 路由方案选择文件路由（方案 A），因为与现有 12 个路由文件风格一致
- 用户模型直接扩展现有 src/models/user.py，不新建模型文件
- 密码哈希用 bcrypt（项目 requirements.txt 已有此依赖）

## 核心产出（我产出了什么）
### POST /api/v1/users
- 入参: { username: str(3-20字符), email: str(valid email), password: str(8-32字符) }
- 成功: 201 { id, username, email, created_at }
- 失败: 409 { error: "USERNAME_EXISTS" } | 422 { error: "INVALID_EMAIL", field: "email" }

### ❌ 坏的设计输出
建议使用微服务架构，引入消息队列处理用户注册。
用户模块负责所有用户相关功能。
接口使用 RESTful 风格。
（没有输入分析、没有决策理由、没有具体接口定义）
```

#### 质量门控（怎么确保质量）
<!-- → 提取到 Skill: architecture -->

| 检查项 | FAIL 条件 |
|--------|----------|
| 扫描现有代码结构 | Handoff 未体现扫描结果 |
| 接口错误场景定义 | 存在无错误场景的接口 |
| 需求范围守护 | 引入了需求文档未提及的功能 |
| 模块边界说明 | 未说明"负责/不负责" |
| 新依赖理由 | 新引入依赖/框架未说明理由 |
| 关键决策多方案对比 | 关键架构决策只给出单一方案 |

#### 输出前自检清单（Subagent Prompt 必须包含）
<!-- → 提取到 Skill: architecture -->

> 参考 Gemini 提示词实践指南「自我批判」原则：在给出最终 Handoff 前，逐条回答以下问题。任何一项为「否」→ 修正后再输出。

1. clarify 中的每条规则，我是否都有对应的接口或数据模型？（逐条核对，列出覆盖表）
2. 每个接口是否都定义了错误场景和错误码？（不能只有正常路径）
3. 我是否扫描了现有代码并保持风格一致？（列出扫描了哪些文件）
4. 关键架构决策是否给出了 2+ 个备选方案的对比？
5. 是否引入了 clarify 文档未提及的功能？（如是，必须删除）
6. 如果我做了任何假设（clarify 未明确的），是否已标注为「待确认」？

---

### 4.2 Plan（开发计划）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-planner.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `architecture`（引用）、`review-standard`（引用，用于 Design 评审）
**Skill 入口**: `/plan`（`context: fork`, `agent: pipeline-planner`）
**工具**: Read, Write, Glob, Grep
**输入**: `handoff_clarify.md` + `handoff_design.md`
**输出**: `handoff_plan.md`

#### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **任务太大** | "实现用户认证模块"作为一个任务 | 开发者无法判断完成度，容易虚假完成 |
| **AC 不可测试** | "界面友好"、"性能良好" | QA 无法验收，结果变成主观判断 |
| **依赖分析缺失** | 任务顺序不对，后面的任务依赖前面未完成的 | 执行时卡住或跳步 |
| **未考虑现有文件** | 不知道该改哪些文件，新建了不该建的文件 | 代码散落、违反项目规范 |

#### 质量标准

- **任务粒度**：单个任务改动 ≤ 5 个文件，可在一次 commit 中完成
- **AC 可测试**：每个 AC 可以翻译成一条 assert 语句或一个具体的测试场景（给出输入 → 期望输出）
- **文件明确**：每个任务列出需要新建和修改的具体文件路径（基于 Glob 扫描现有代码得出）
- **依赖清晰**：标注 `depends_on: [Task N]`，执行顺序无歧义

#### 理解输入 + 验证输出（原则 5 的具体应用）

**理解输入**：Planner 在开始拆分任务前，必须理解两份上游文档：

1. **理解 clarify 的规则和示例**：
   - 每条规则的业务行为 → 判断任务拆分粒度
   - 正例/反例 → 推导每个任务的 AC（可直接引用）
   - 排除项 → 明确不拆分的范围

2. **理解 design 的接口和模块**：
   - 接口间的依赖关系 → 推导任务执行顺序
   - 模块边界 → 推导任务的文件范围和隔离性
   - 数据模型 → 判断哪些任务必须串行（共享数据表）

```
### ✅ 好的理解输入
读取 handoff_clarify.md：3 条规则（注册/登录/密码校验），排除邮箱验证。
读取 handoff_design.md：POST /api/users 依赖 User 模型，POST /api/auth/login 依赖 User + JWT。
→ 拆分方向：T1 创建 User 模型（被 T2/T3 依赖），T2 注册 API，T3 登录 API。
  T2/T3 文件不重叠，可并行。

### ❌ 坏的理解输入
读取了 handoff_clarify.md 和 handoff_design.md。
按技术层拆分：Model → Service → API → 前端。
（没有从规则和接口推导拆分方向，机械按技术层切分）
```

**验证输出**：Planner 在输出计划前，必须验证任务覆盖了所有设计接口和 clarify 规则：

| clarify 规则 | 对应的设计接口 | 对应的 Task | 覆盖状态 |
|-------------|--------------|-----------|---------|
| 规则 1: 用户注册 | POST /api/users | T2 | ✅ |
| 规则 2: 登录 | POST /api/auth/login | T3 | ✅ |
| 规则 3: 密码校验 | User.validate_password | T1 | ✅ |

如有规则无对应 Task → 计划不完整，不能输出。

#### Few-shot 示例

```
### ✅ 好的计划输出
## 输入分析
读取 handoff_design.md 发现 3 个接口（注册/登录/查询），数据模型 1 个（User）。
扫描现有代码：src/models/ 有 5 个模型文件，src/api/v1/ 有 12 个路由文件。

## 决策及理由
拆为 2 个任务而非 1 个，因为数据模型和 API 路由改动不同文件，独立可测试。
Task-2 依赖 Task-1，因为 API 需要调用 User.create()。

## 任务清单
### Task-1: 创建用户数据模型
- 文件: src/models/user.py（修改）, tests/test_models/test_user.py（新建）
- AC:
  - AC1: User.create(username="test", email="t@t.com", password="12345678") 成功返回 User 实例，id 非空
  - AC2: User.create(username="te", ...) 抛出 ValidationError，message 包含 "username"
  - AC3: User.create(username=已存在的用户名, ...) 抛出 IntegrityError
- depends_on: []

### Task-2: 创建用户注册 API
- 文件: src/api/v1/users.py（新建）, tests/test_api/test_users.py（新建）
- AC:
  - AC1: POST /api/v1/users {"username":"test",...} → 201 {"id":..., "username":"test"}
  - AC2: POST /api/v1/users {"username":"te",...} → 422 {"error":"INVALID_USERNAME"}
- depends_on: [Task-1]

### ❌ 坏的计划输出
## Task-1: 实现用户注册功能
- 实现完整的用户注册流程
- AC: 用户可以注册，界面友好，性能良好
- 涉及文件: 用户相关文件
（无输入分析、无拆分理由、任务太大、AC 不可测试、文件不明确）
```

#### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| AC 可测试性 | 存在无法翻译成 assert 的 AC |
| 任务粒度 | 单个任务改动超过 5 个文件 |
| 文件路径明确 | 任务未列出具体文件路径 |
| 依赖拓扑 | 依赖关系存在循环 |
| 需求覆盖 | 任务总数未覆盖需求文档全部功能点 |

#### 输出前自检清单（Subagent Prompt 必须包含）

1. 每条 clarify 规则 → 是否都有对应的 Task 覆盖？（列出覆盖表）
2. 每个 AC 是否能翻译成一条 assert 语句或具体的测试场景？
3. 每个 Task 是否列出了具体的文件路径（基于 Glob 扫描）？
4. Task 之间是否有循环依赖？（画出依赖链确认）
5. 单个 Task 改动是否超过 5 个文件？（超过则需拆分）
6. 如果我做了任何假设，是否已标注？

#### 评审上游：Design 审查
<!-- → 提取到 Skill: review-standard（Design 评审标准部分） -->

> Planner 在正常规划任务之外，还承担 Design 文档的评审职责。pipeline.sh 在 Designer 输出 handoff_design.md 后，调用 Planner 进入评审模式。

**评审时机**：Designer 输出 `handoff_design.md` 后，pipeline.sh 调用 Planner 进入评审模式。

**评审标准（DESIGN_OK vs DESIGN_ISSUE）**：

| 检查项 | DESIGN_ISSUE 条件 |
|--------|------------------|
| clarify 规则覆盖 | 存在 clarify 规则没有对应的接口或数据模型 |
| 接口完整性 | 接口定义缺少错误场景、参数校验规则 |
| 可执行性 | 模块边界模糊到无法拆分为具体任务 |
| 过度设计 | 引入了 clarify 未要求的抽象层或设计模式 |
| 数据模型 | 数据模型无法支撑所有 clarify 正例的数据流 |

**输出文件**：`review_design_N.md`（N = 评审轮次编号）

**输出格式**：
```
REVIEW: DESIGN_OK
（或）
REVIEW: DESIGN_ISSUE

## Issues
1. [具体问题 + 在 handoff_design.md 中的位置 + 修改建议]
```

**自检清单（评审模式专用）**：
1. 是否逐条核对了 clarify 规则与 design 接口的对应关系？
2. 是否以"能否拆分为可执行任务"的视角审视设计粒度？
3. DESIGN_ISSUE 是否给出了具体位置和修改建议（而非泛泛的"不够完善"）？

---

### 4.3 Run-Plan（执行开发）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-implementer.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `tdd-methodology`（主用）、`code-quality`（引用）
**Skill 入口**: `/run-plan`（`context: fork`, `agent: pipeline-implementer`）
**工具**: Read, Write, Edit, Bash, Glob, Grep
**输入**: `handoff_plan.md` + `handoff_design.md`
**输出**: `handoff_run.md`

#### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **跳过 TDD** | 先写实现再补测试，或不写测试 | 测试覆盖不全，Bug 漏到 QA |
| **虚假完成** | 代码是占位符，或只实现了正常路径 | Check/QA 阶段大量失败 |
| **偏离设计** | 不按设计文档实现，自行发挥 | 模块边界混乱，接口不一致 |
| **一个大 commit** | 所有改动一次提交 | 无法追溯、无法回退单个任务 |

#### 质量标准
<!-- → 提取到 Skill: tdd-methodology -->

- **严格 TDD**：每个任务的执行顺序是——写测试 → 运行确认失败 → 写实现 → 运行确认通过
- **一任务一 commit**：commit message 引用 Task 编号，格式 `feat(Task-1): 描述`
- **每个 commit 必须包含测试**：无测试文件的 commit 不允许
- **阻塞标注**：任务无法完成时标注 BLOCKED + 原因，不跳过不假装完成

#### Few-shot 示例
<!-- → 提取到 Skill: tdd-methodology -->

```
### ✅ 好的执行输出
## 输入分析
读取 handoff_plan.md：Task-1 要求创建用户数据模型，AC 有 3 条（创建/校验/唯一性）。
读取 handoff_design.md：接口定义 username 为 3-20 字符，需校验。
文件清单：修改 src/models/user.py，新建 tests/test_models/test_user.py。

## 决策及理由
按设计文档定义的校验规则实现（3-20 字符），不自行调整范围。
validate_username 放在模型层而非 API 层，因为设计文档要求模型层校验。

## Task-1 执行记录
### 测试先行
运行: pytest tests/test_models/test_user.py → 3 FAILED (test_create_user, test_username_validation, test_duplicate_username)
### 实现
修改 src/models/user.py: 添加 username 字段(String(20), unique=True, nullable=False) + validate_username 方法
### 验证
运行: pytest tests/test_models/test_user.py → 3 PASSED
### Commit
`feat(Task-1): 添加用户数据模型及校验`，包含 src/models/user.py + tests/test_models/test_user.py

### ❌ 坏的执行输出
已完成用户模型的开发。代码已写好，测试也通过了。
（无输入分析、无决策理由、无 TDD 证据、无测试运行记录、无 commit 信息）
```

#### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 任务-commit 对应 | 存在任务无对应 commit |
| commit 含测试 | 存在不含测试文件的 commit |
| 完成度真实性 | 任务标记完成但测试未通过 |
| BLOCKED 说明 | BLOCKED 任务未说明原因 |
| 设计一致性 | 实现偏离设计文档的接口定义 |

#### 输出前自检清单（Subagent Prompt 必须包含）

1. 每个 Task 是否都有对应的 commit？（列出 Task-commit 对照表）
2. 每个 commit 是否包含测试文件？
3. 是否有跳过 TDD 流程（先写实现再补测试）的情况？
4. 是否有标记 BLOCKED 但未说明原因的任务？
5. 实现是否偏离了 design 文档的接口定义？（逐接口核对）
6. 如果有任何遗留问题，是否已在 Handoff 中明确标注？

#### 评审上游：Plan 审查

> Implementer 在正常执行开发之外，还承担 Plan 文档的评审职责。pipeline.sh 在 Planner 输出 handoff_plan.md 后，调用 Implementer 进入评审模式。

**评审时机**：Planner 输出 `handoff_plan.md` 后，pipeline.sh 调用 Implementer 进入评审模式。

**评审标准（PLAN_OK vs PLAN_ISSUE）**：

| 检查项 | PLAN_ISSUE 条件 |
|--------|-----------------|
| 文件路径 | 任务中引用的文件路径不存在或不正确（通过 Glob 验证） |
| AC 可测性 | AC 无法直接翻译为 assert 语句 |
| 依赖拓扑 | 任务依赖存在循环或顺序矛盾 |
| 任务粒度 | 单个任务涉及 >5 个文件，无法一次 commit |
| 设计一致性 | 任务要求与 handoff_design.md 的接口定义矛盾 |

**输出文件**：`review_plan_N.md`（N = 评审轮次编号）

**输出格式**：
```
REVIEW: PLAN_OK
（或）
REVIEW: PLAN_ISSUE

## Issues
1. [具体问题 + 在 handoff_plan.md 中的位置 + 修改建议]
```

**自检清单（评审模式专用）**：
1. 是否逐条核对了每个任务的文件路径是否真实存在（通过 Glob 验证）？
2. 是否以"能否翻译为 assert"的视角审视每个 AC？
3. PLAN_ISSUE 是否给出了具体位置和修改建议（而非泛泛的"不够完善"）？

---

### 4.4 Check（代码检查）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-checker.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `code-quality`（主用）、`review-standard`（主用）
**Skill 入口**: `/check`（`context: fork`, `agent: pipeline-checker`）
**工具**: Read, Bash, Glob, Grep（只读，不能修改代码）
**输入**: `handoff_plan.md` + `handoff_run.md`
**输出**: `handoff_check.md`

#### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **只跑测试** | 测试通过就说 PASS，不检查其他维度 | 代码质量问题漏到 QA |
| **主观判断** | "代码看起来不错"、"结构合理" | 不可验证，形式主义 |
| **不对照 AC** | 只做通用检查，不验证计划中的具体 AC | 功能遗漏未发现 |
| **漏掉检查维度** | 忘了跑 lint 或 type 检查 | 低级问题遗留 |

#### 质量标准
<!-- → 提取到 Skill: code-quality -->

- **五维检查，缺一不可**：
  1. 测试：运行全量测试，记录通过/失败数
  2. Lint：运行 ruff/eslint，记录告警数
  3. 类型检查：运行 mypy/tsc（如项目配置了）
  4. 代码质量规则：函数长度 ≤40 行、参数 ≤5 个、嵌套 ≤3 层、无空 catch、无裸 except、无硬编码
  5. AC 覆盖：逐条核对计划文档中每个任务的 AC
- **每项必须有客观证据**：命令输出、文件路径:行号、具体数值
- **结论只有 PASS/FAIL**：五维全 PASS 才是 PASS

#### Few-shot 示例

```
### ✅ 好的检查输出
## 输入分析
读取 handoff_plan.md：2 个任务，共 5 条 AC。
读取 handoff_run.md：2 个 commit，无 BLOCKED 任务。

## 决策及理由
按五维检查逐一执行，不跳过任何维度。
AC 覆盖以 handoff_plan.md 中的 AC 列表为准，逐条核对。

## 五维检查结果
### 1. 测试
运行: pytest --tb=short → 47 passed, 2 failed
- FAIL: tests/test_api/test_users.py::test_duplicate_email → AssertionError: expected 409, got 500
- FAIL: tests/test_api/test_users.py::test_empty_password → ValidationError not raised

### 2. Lint
运行: ruff check src/ → 3 warnings
- src/api/v1/users.py:42: E501 line too long (127 > 120)
- src/models/user.py:15: F401 'datetime' imported but unused
- src/models/user.py:67: W291 trailing whitespace

### 3. 类型检查
运行: mypy src/ → 0 errors（项目已配置 mypy.ini）

### 4. 代码质量规则
- 函数长度: 全部 ≤40 行 ✅
- 参数数量: create_user() 有 6 个参数 ❌（超过 5 个，src/api/v1/users.py:28）
- 嵌套深度: 全部 ≤3 层 ✅
- 空 catch / 裸 except: 无 ✅

### 5. AC 覆盖
| Task | AC | 状态 | 证据 |
|------|-----|------|------|
| Task-1 | AC1: 创建用户 | PASS | test_create_user passed |
| Task-1 | AC2: 用户名校验 | PASS | test_username_validation passed |
| Task-2 | AC1: 注册 API 201 | PASS | test_register_user passed |
| Task-2 | AC2: 重复邮箱 409 | FAIL | test_duplicate_email: got 500 |

RESULT: FAIL（测试 2 FAIL + 代码质量 1 FAIL）

### ❌ 坏的检查输出
代码质量良好，测试基本通过，结构合理。建议优化部分命名规范。整体评价：PASS
（无输入分析、无五维检查、无具体数据、主观判断）
```

#### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 五维完整性 | 缺少任何一个检查维度 |
| FAIL 项证据 | FAIL 项缺少文件路径和行号 |
| 客观性 | 报告中存在主观描述（无客观证据支撑） |
| AC 逐条覆盖 | AC 覆盖检查未逐条列出状态 |

#### 输出前自检清单（Subagent Prompt 必须包含）

1. 五维检查是否全部执行？（测试/Lint/类型检查/代码质量规则/AC 覆盖）
2. 每个 FAIL 项是否有客观证据（命令输出/文件路径:行号）？
3. 报告中是否存在「看起来不错」「结构合理」等主观描述？（如有，替换为客观证据）
4. AC 覆盖表是否逐条列出了每个 AC 的状态和证据？
5. 结论是否严格基于检查结果（五维全 PASS 才 PASS）？
6. pipeline.sh 会在你完成后独立运行测试判定 PASS/FAIL。你的职责是检查并描述问题，无权判定 PASS/FAIL。
7. Handoff 中是否包含 `RESULT: PASS` 或 `RESULT: FAIL` 摘要？（供人阅读参考，非 pipeline.sh 判定依据）

---

### 4.5 QA（验收测试）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-qa.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `qa-methodology`（主用）
**Skill 入口**: `/qa`（`context: fork`, `agent: pipeline-qa`）
**工具**: Read, Bash, Glob, Grep（只读，不能修改代码）
**输入**: `handoff_clarify.md`（需求文档，验收唯一标准）+ `handoff_design.md`（接口定义，用于构造端到端验证的请求参数）
**输出**: `handoff_qa.md`

#### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **重复 Check 的工作** | 又跑一遍测试和 lint，没有独立价值 | 浪费资源，不产生新发现 |
| **标准偏移** | 以计划文档或设计文档为验收标准 | 验收的是"计划"而非"需求" |
| **只验正常路径** | 不测试边界条件和排除项 | 用户使用时遇到未处理的边界场景 |
| **测试通过=功能正确** | 认为 Check 通过就等于功能满足需求 | "代码正确"不等于"功能正确" |

#### 质量标准
<!-- → 提取到 Skill: qa-methodology -->

- **验收标准的唯一来源**：`handoff_clarify.md`（需求文档），不是 plan 不是 design
- **接口信息来源**：`handoff_design.md` 仅用于获取接口路径和参数格式，不作为验收标准
- **与 Check 的分工**：Check 验证"代码质量"，QA 验证"功能是否满足需求"
- **逐条需求覆盖**：需求文档中的每条规则及其正例/反例，逐条给出 PASS/FAIL + 证据
- **边界条件必测**：需求文档中的排除项和边界条件也必须验证
- **端到端视角**：从用户使用的角度验证，而非从代码实现的角度
- **验证方式：真实服务**：QA 必须启动真实服务进行端到端验证（test client 绕过中间件/CORS/连接池等，发现问题的真实度不够）。QA SubAgent 负责在 Bash 中执行：启动服务 → 健康检查等待就绪 → 端到端测试 → 停止服务。pipeline.sh 中 QA 步骤的 `STEP_TIMEOUT` 应适当增大以容纳服务启停时间

#### Few-shot 示例

```
### ✅ 好的 QA 输出
## 输入分析
读取 handoff_clarify.md：功能清单 F1 用户注册（3 条规则）+ 排除项（不含邮箱验证流程）。
读取 handoff_design.md：接口定义 POST /api/v1/users，入参 username/email/password，成功 201，失败 409/422。

## 决策及理由
以 handoff_clarify.md 为唯一验收标准，handoff_design.md 仅用于获取接口路径和参数格式。
独立执行端到端验证（使用项目 test client），不依赖 Checker 的测试结果。

## 逐条验收
### F1: 用户注册
| 规则 | 期望行为 | 实际行为 | 状态 | 验证方式 |
|----|---------|---------|------|---------|
| 规则1: 正常注册 | POST /api/v1/users → 201 | 201 {"id":1,"username":"test"} | PASS | curl -X POST ... |
| 规则2: 重复用户名 | → 409 USERNAME_EXISTS | 409 {"error":"USERNAME_EXISTS"} | PASS | 先注册后重复 |
| 规则3: 密码少于8位 | → 422 INVALID_PASSWORD | 500 Internal Server Error | FAIL | curl -d '{"password":"123"}' |

### F1-规则3 失败详情
- 期望: 422 {"error":"INVALID_PASSWORD","field":"password"}
- 实际: 500 Internal Server Error（密码校验未实现，直接抛 DB 异常）
- 复现: curl -X POST localhost:8000/api/v1/users -d '{"username":"test","email":"t@t.com","password":"123"}'

RESULT: FAIL

### ❌ 坏的 QA 输出
测试全部通过，功能正常。代码质量良好。RESULT: PASS
（无输入分析、未读 design 获取接口定义、无逐条覆盖、无端到端验证）
```

#### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 验收标准来源 | 未以 handoff_clarify.md 为唯一标准 |
| 功能点覆盖 | 需求文档中的功能点未全部覆盖 |
| FAIL 项三要素 | FAIL 项缺少期望行为/实际行为/复现方式 |
| 边界条件验证 | 边界条件和排除项未验证 |
| 与 Check 差异化 | 验证方式与 Check 重复（重复跑测试） |

#### 输出前自检清单（Subagent Prompt 必须包含）

1. 验收标准来源是否为 handoff_clarify.md？（clarify 是唯一验收标准，design 仅用于获取接口路径和参数格式）
2. clarify 中的每条规则及其正例/反例，是否都逐条验证了？（列出覆盖表）
3. 排除项和边界条件是否验证了？
4. 验证方式是否与 Checker 有差异化？（不是重复跑 pytest/lint）
5. FAIL 项是否有期望行为 + 实际行为 + 复现命令三要素？
6. pipeline.sh 会在你完成后独立运行测试判定 PASS/FAIL。你的职责是逐条验收并描述发现的问题，无权判定 PASS/FAIL。
7. Handoff 中是否包含 `RESULT: PASS` 或 `RESULT: FAIL` 摘要？（供人阅读参考，非 pipeline.sh 判定依据）

---

### 4.6 Fix（修复）

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->
<!-- 本节中标注"→ 提取到 Skill: xxx"的内容将从 SubAgent 文件中移出，放入对应的 Skill 知识层文件 -->

**SubAgent**: `pipeline-fixer.md`（精简角色卡，< 3k tokens）
**引用 Skills**: `tdd-methodology`（主用）、`code-quality`（引用）
**Skill 入口**: `/fix`（`context: fork`, `agent: pipeline-fixer`）
**工具**: Read, Write, Edit, Bash, Glob, Grep
**输入**: `handoff_qa.md` + `handoff_check.md`
**输出**: `handoff_fix_N.md`

#### 常见失败模式

| 失败模式 | 表现 | 后果 |
|---------|------|------|
| **创可贴修复** | 只消除症状，不解决根因 | 问题换个形式再次出现 |
| **重复失败方案** | 第 3 次修复还在用第 1 次的方法 | 死循环，浪费 fix 次数 |
| **降级修复** | 删除测试、降低标准、注释代码 | 违反铁律，质量倒退 |
| **修一个坏两个** | 修复引入新 Bug | 越修越多，fix 循环收敛不了 |

#### 质量标准

- **根因分析**：每个 FAIL 项先分析根因，再决定修复方案
- **差异说明**（第 2 次及以后）：必须说明上次修复为什么失败、这次方案有何不同
- **最小修改**：只改必要的代码，不顺手重构不相关的部分
- **回归测试**：每个修复必须添加针对性的回归测试
- **修复后自验**：运行相关测试确认通过，再输出 Handoff

#### Few-shot 示例

```
### ✅ 好的修复输出
## 输入分析
读取 handoff_qa.md：1 个 FAIL 项（F1-AC3 密码少于8位返回 500，期望 422）。
读取 handoff_check.md：对应测试 test_empty_password 也 FAILED，确认是同一问题。
这是第 1 次修复，无历史修复记录。

## 根因分析（决策及理由）
src/api/v1/users.py:35 的 create_user() 直接调用 db.session.add()，
未先调用 User.validate() 校验密码长度。当密码 < 8 位时，
DB 层的 CHECK 约束抛出 IntegrityError，被全局异常处理器捕获为 500。

修复方案：在 db.session.add() 之前添加 User.validate(data) 调用。
选择此方案而非在 API 层加 if 判断，因为设计文档要求校验逻辑统一在模型层。

## 修复产出
### 修改文件
- src/api/v1/users.py:35: 添加 `User.validate(data)` 调用
- tests/test_api/test_users.py: 添加 test_short_password_returns_422 回归测试

### 验证
修复前: pytest tests/test_api/test_users.py::test_short_password → FAILED (500)
修复后: pytest tests/test_api/test_users.py::test_short_password → PASSED (422)
全量: pytest → 49 passed, 0 failed（修复前 47 passed, 2 failed）

### ❌ 坏的修复输出
已修复密码校验问题。添加了相关代码。测试通过。
（无输入分析、无根因分析、无修复前后对比）
```

#### 质量门控

| 检查项 | FAIL 条件 |
|--------|----------|
| 根因分析 | FAIL 项缺少根因分析 |
| 差异说明（N > 1） | 未说明与上次修复的差异 |
| 降级修复检测 | 修复涉及删除测试或降低标准 |
| 回归测试 | 未添加回归测试 |
| 修复有效性 | 修复后相关测试未通过 |
| 回归安全 | 修复引入了新的测试失败 |

#### 输出前自检清单（Subagent Prompt 必须包含）

1. 每个 FAIL 项是否做了根因分析？（不是直接改代码）
2. 如果是第 2 次及以后修复，是否说明了与上次修复方案的差异？
3. 修复是否只改了必要的代码？（没有顺手重构不相关的部分）
4. 是否添加了针对性的回归测试？
5. 修复后是否运行了相关测试并确认通过？
6. 是否有通过删除测试或降低标准来「修复」的情况？（绝对禁止）

---

### 4.7 Ship（交付）

**Skill 入口**: `/ship`（现有）
**工具**: Read, Bash
**输入**: `handoff_clarify.md` + `handoff_qa.md`
**输出**: PR URL

此步骤需用户确认后执行（不可逆操作），不纳入自动编排。

**附带清理**：`/ship` 完成后，清理进度文件（`.pipeline-progress-{feature}.json`），将 Pipeline 目录移至 `docs/pipeline/archive/`。

---

## 5. Handoff 文档规范

### 5.1 设计原则

- **自包含**：每个 Handoff 文档包含下一步执行所需的全部信息
- **结构化**：固定格式，便于后续 Subagent 解析
- **可追溯**：保留在 `docs/pipeline/` 目录，全流程可回溯

### 5.2 通用格式

```markdown
# Handoff: [步骤名]

**功能名**: [feature_name]
**执行时间**: [timestamp]
**执行结果**: PASS / FAIL / BLOCKED

---

## 输入分析（我看到了什么）
[读取了哪些文件、扫描了什么、发现了什么关键信息]

## 决策及理由（我决定做什么）
[为什么选择方案 A 而非方案 B、关键取舍的理由]

## 核心产出（我产出了什么）
[本步骤的主要输出内容]

## 交接项
[按 Section 4.0 原则 4 定义的固定传递项，各步骤内容不同，见原则 4 表格]

## 修改的文件
- file1.py: [改动描述]
- file2.ts: [改动描述]
```

### 5.3 Subagent 中的文件引用方式

Subagent 通过 prompt 传入具体文件路径（含 feature 命名空间），在执行时用 Read 工具读取：

```
自动模式（pipeline.sh 注入 prompt）:
"请读取 docs/pipeline/用户管理/handoff_design.md 和 docs/pipeline/用户管理/handoff_clarify.md，
然后基于设计文档和需求文档编写开发计划，输出到 docs/pipeline/用户管理/handoff_plan.md"

手动模式（Skill 中 Task 工具调用）:
Skill 负责拼接当前 feature 的路径，传给 Subagent
```

不使用管道输入，避免 prompt 过大浪费 token。

---

## 6. /clarify 升级方向

### 6.1 当前问题

现有 `/clarify` 存在三个核心缺陷：

1. **Slot Filling 无法暴露隐含假设**：只能收集用户已经意识到的信息，用户没说出来的假设（"当然是这样的，这还用说？"）永远收集不到。
2. **抽象 AC 无法验证理解对齐**：用户说"做通知功能"，Claude 说"收到"，双方都觉得理解一致，但各自想的可能完全不同。缺乏具体的验证手段。
3. **苏格拉底式被误定义为"质疑方向"**：设计方向偏向质疑需求的必要性/可行性，偏离了核心目标——确保双方对"做什么"的理解完全一致。

### 6.2 升级要点

| 维度 | 当前 | 升级后 |
|------|------|--------|
| 苏格拉底的角色 | 质疑方向（挑战决定） | 暴露隐含假设（对齐理解） |
| 执行方式 | 两阶段分离（先收集再质疑） | 逐点循环（提问 → 示例 → 确认） |
| 验证手段 | 无 | Example Mapping（正例 + 反例） |
| 输出格式 | Given/When/Then AC 表格 | Rules + Examples（结构化场景） |
| 质疑方向 | 独立阶段 | 自然产物（证据驱动的追问） |
| 后续触发 | 无 | 完成后主动提示是否启动自动流程 |

### 6.3 第零步：先理解背景再提问

> **核心问题**：如果 clarify 不了解项目背景就开始提问，用户会感觉"对牛弹琴"——问题没有针对性，浪费用户精力在已知信息上。

clarify 在向用户提出任何问题之前，必须先静默完成背景理解：

```
用户输入需求
    │
    ▼
┌─────────────────────────────────────┐
│ 第零步：理解背景（静默，不向用户提问）   │
│                                     │
│  1. 项目全局（CLAUDE.md + README.md） │
│     → 技术栈、架构模式、约定          │
│  2. 相关代码逻辑（限制范围）           │
│     → 只读最近修改的 5-10 个关键文件    │
│     → 避免全量阅读导致 TTFT 过高       │
│  3. 相关规范约束                     │
│     → 项目规则、团队约定              │
│  4. 相关历史（已有的设计/需求文档）     │
│     → 避免重复已解决的问题             │
│                                     │
│  内部梳理：                           │
│  ┌──────────┬──────────┬──────────┐ │
│  │ 已知信息  │ 未知信息  │ 约束条件  │ │
│  └──────────┴──────────┴──────────┘ │
│  复杂度从"未知信息数量"自然得出，       │
│  不靠机械打分表                       │
└─────────────────┬───────────────────┘
                  │
                  ▼
          进入第一步：目标锚定
```

**关键区别**：
- ❌ 旧做法：复杂度评估（打分表）为主，背景研究为辅 → 背景理解沦为形式
- ✅ 新做法：背景理解为主，复杂度从未知信息数量自然得出 → 提问有针对性

**为什么重要**：了解背景后，提问质量显著提升——不会问用户已在 CLAUDE.md 中说明的技术栈，不会忽视项目已有的约定，不会重复已解决的问题。用户感受从"对牛弹琴"变为"这个人做了功课"。

#### 第零步约束（防止静默阶段过长）

> 静默阶段如果不加约束，用户可能以为 Claude 卡死了。

1. **时间限制**：最多花 30 秒读取背景，不追求完美理解
2. **范围限制**：只读以下文件，不全量扫描项目
   - `CLAUDE.md` / `README.md`（必读）
   - 最近修改的 5 个关键源文件（用 `git log --diff-filter=M -5` 判断）
   - 现有的设计/需求文档（`docs/` 下）
3. **用户反馈**：如果预计超过 10 秒，先输出一句话：「我在了解项目背景，大约需要 xx 秒...」
4. **止损原则**：不要试图理解整个项目，只需要理解与本次需求相关的上下文

---

### 6.4 方法论：苏格拉底提问 + Example Mapping 验证

#### 理论依据

**苏格拉底六类问题**（R.W. Paul）适配为需求澄清的五类提问：

| 问题类型 | 目的 | 需求澄清中的应用 |
|---------|------|-----------------|
| **澄清类** | 消除歧义词 | "你说的'通知'具体指系统推送还是站内消息？" |
| **假设探测** | 暴露隐含假设 | "你假设用户都在线，如果离线呢？" |
| **后果推演** | 发现边界条件 | "如果并发量增长 10 倍，这个设计会怎样？" |
| **示例验证** | 用具体场景验证理解 | "比如用户 A 评论了 B 的文章，B 应该看到什么？" |
| **反例构造** | 用反例暴露遗漏 | "如果 B 已经删除了这篇文章，通知还应该发吗？" |

**Example Mapping**（Cucumber 团队实践，需求缺陷从 7-8 个降至 0-1 个）：

- 具体示例是暴露理解偏差的最有效工具
- 正例验证"该做什么"，反例验证"不该做什么"，待确认项标记"不确定的"
- 每轮只问 1-2 个问题（LLMREI 研究验证：一次问太多，用户回答质量下降）

#### 执行流程

```
用户输入需求
    │
    ▼
┌─────────────────────────────┐
│ 第零步：理解背景（静默）      │  ← 详见 6.3
│ 项目全局 → 相关代码 →        │
│ 规范约束 → 历史文档           │
│ → 内部梳理已知/未知/约束      │
└─────────────┬───────────────┘
              │
              ▼
┌─────────────────────────────┐
│ 第一步：目标锚定             │  ← Impact Mapping 的 Why/Who
│ "这个功能要解决什么问题？"    │
│ "谁在用？什么场景下用？"     │
└─────────────┬───────────────┘
              │
              ▼
┌─────────────────────────────┐
│ 第二步：逐点深挖循环          │  ← 苏格拉底 + Example Mapping
│                             │
│  对每个关键点：               │
│  ① 苏格拉底提问（暴露盲区）  │
│  ② 生成具体示例（验证理解）  │
│  ③ 用户确认或修正            │
│  ④ 进入下一个点              │
│                             │
│  每轮 1-2 个问题             │
└─────────────┬───────────────┘
              │
              ▼
┌─────────────────────────────┐
│ 第三步：结构化复述            │  ← 回声确认
│ "我的理解是：[Rules+Examples]"│
│ "不确定项：[待确认问题]"      │
└─────────────┬───────────────┘
              │
              ▼
        用户确认 → 输出 handoff
```

#### "质疑方向"的定位

质疑方向不是独立阶段，而是逐点深挖的**自然产物**：

```
当构造示例和反例时，如果发现：
- 核心场景很少 → 自然引出 "这个功能的使用频率有多高？"
- 实现复杂度远超收益 → 自然引出 "有没有更简单的方式达到同样效果？"

→ 质疑是基于具体证据的自然追问，不是空泛的"你确定要做吗？"
```

不做质疑的场景：Bug 修复、明确的技术债务清理、用户已深思熟虑且提供了充分理由的功能。

#### Few-shot 示例

```
### ✅ 好的澄清对话（示例驱动 + 暴露隐含假设）

用户："我要做一个通知功能。"

Claude："我理解你要做通知功能。让我用一个具体场景确认——
  当用户 A 评论了用户 B 的文章时，
  用户 B 在 5 秒内看到一个红点提示，
  点击后看到评论内容。
  这是你要的效果吗？"

用户："不是，不需要红点，只要打开通知页面时能看到就行。"

Claude："明白。那如果用户 B 一直不打开通知页面，
  这些通知会一直累积吗？有没有保留期限？"

→ 一个具体示例就暴露了"实时推送"和"红点提示"两个隐含假设

### ❌ 坏的澄清（空泛质疑 / 纯 Slot Filling）

用户："我要做一个通知功能。"

Claude："你确定需要通知吗？用户真的会用吗？"
（空泛质疑，没有依据，纯增加摩擦）

或者：

Claude："通知类型有哪些？用户量多少？延迟要求？"
（纯 Slot Filling，用户回答完双方仍可能理解不一致）
```

### 6.5 输出格式

`/clarify` 完成后输出 `docs/pipeline/{feature_name}/handoff_clarify.md`：

```markdown
# Handoff: Clarify

**功能名**: [feature_name]
**确认时间**: [timestamp]

---

## 需求概述
[一句话描述功能目标和核心场景]

## 功能规则与示例

### 规则 1: [规则名称]
[一句话描述规则]

- ✅ [正例：输入/条件 → 期望结果]
- ✅ [正例：另一个场景 → 期望结果]
- ❌ [反例：不应该发生的场景 → 期望处理方式]
- ❓ [待确认项：无法确定的场景]（待确认）

### 规则 2: [规则名称]
...

## 排除项
- [明确不做的事情]

## 技术约束
- [项目级约束，如技术栈、兼容性要求]
```

**粒度标准**：clarify 确保**方向和范围无歧义**，技术实现细节由 design 阶段补充。Rules + Examples 格式让 design 阶段可以直接从每条规则推导接口和数据模型。

**输出前自检（/clarify Prompt 必须包含）**：
1. 对话中提到但未写入 Handoff 的信息是否存在？（如有，补充到文档中或标注为待确认项）
2. 每条规则是否至少有 1 个正例和 1 个反例？
3. 排除项是否明确列出？
4. 是否存在用户未意识到的隐含假设？（如有，标注为待确认项）

---

## 7. 三层架构：Skills、SubAgents 与 pipeline.sh

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

### 7.1 三层架构总览

```
┌─────────────────────────────────────────────────────────────────┐
│  编排层：pipeline.sh / Skill (context: fork)                      │
│  职责：确定性流程控制、触发执行                                      │
│  不关心方法论内容                                                   │
├─────────────────────────────────────────────────────────────────┤
│  执行层：SubAgents（精简角色卡，< 3k tokens）                       │
│  职责：角色身份 + 行为边界 + 输入输出规范 + 负向约束                  │
│  通过 skills 字段引用知识层                                         │
├─────────────────────────────────────────────────────────────────┤
│  知识层：Skills（可复用方法论沉淀）                                   │
│  职责：方法论、经验、质量标准（如 TDD 流程、代码审查标准）              │
│  跨 SubAgent 共享复用                                               │
└─────────────────────────────────────────────────────────────────┘
```

**为什么拆分三层**：

| 问题 | 旧方案（All-in-one SubAgent） | 新方案（三层分离） |
|------|------------------------------|------------------|
| SubAgent 文件臃肿 | 角色+方法论+质量标准混在一起，25k+ tokens | SubAgent 精简到 < 3k tokens，方法论通过 skills 引用 |
| 方法论无法复用 | TDD 方法论在 Implementer 和 Fixer 中各写一份 | TDD 方法论抽取为 `tdd-methodology` Skill，两个 SubAgent 共享 |
| 修改方法论要改多处 | 更新代码质量标准需同时改 Checker 和 QA | 修改 `code-quality` Skill 一处，所有引用者自动生效 |
| Skills 价值被稀释 | Skill 变成薄路由层，失去方法论沉淀价值 | Skill 回归方法论本质，成为经验和标准的载体 |

### 7.2 知识复用矩阵

下表展示哪些 Skills（知识层）被哪些 SubAgents（执行层）引用：

| Skill（知识层） | Designer | Planner | Implementer | Checker | QA | Fixer |
|----------------|:--------:|:-------:|:-----------:|:-------:|:--:|:-----:|
| `architecture`（架构设计方法论） | **主用** | 引用 | - | - | - | - |
| `tdd-methodology`（TDD 流程） | - | - | **主用** | - | - | **主用** |
| `code-quality`（代码质量标准） | - | - | 引用 | **主用** | - | 引用 |
| `review-standard`（代码审查标准） | - | 引用 | - | **主用** | - | - |
| `qa-methodology`（QA 验收方法论） | - | - | - | - | **主用** | - |

**主用** = 该 Skill 是 SubAgent 的核心方法论依据
**引用** = 该 SubAgent 需了解但非核心（如 Implementer 引用 code-quality 用于自检）

### 7.3 两种调用路径

同一份 SubAgent 文件 + 同一套 Skills 有两种调用方式：

```
手动模式: /design Skill (context: fork, agent: pipeline-designer)
          → Claude Code 自动加载 SubAgent + 其 skills 字段声明的所有 Skills
          → 在隔离上下文中执行

自动模式: pipeline.sh
          → claude -p "$(cat pipeline-designer.md) $(cat architecture.md) $(cat ...)" ...
          → pipeline.sh 手动拼接 SubAgent + Skills 内容（CLI 模式不支持 skills 字段自动解析）
          → 独立进程执行
```

**Skills 加载差异及解决方案**：

| 机制 | 手动模式（交互式） | 自动模式（CLI） |
|------|-------------------|----------------|
| SubAgent 加载 | `agent` 字段自动加载 | `$(cat agent.md)` 手动注入 |
| Skills 加载 | `skills` 字段自动注入 | pipeline.sh 读取 SubAgent 文件解析 `skills` 行，拼接对应 Skill 内容 |
| context 隔离 | `context: fork` 原生隔离 | 每次 `claude -p` 天然独立上下文 |

pipeline.sh 中 Skills 拼接的实现方式（伪代码）：
```bash
# 从 SubAgent 文件中解析 skills 字段，自动拼接 Skill 内容
build_prompt() {
  local agent_file="$1"
  local prompt="$(cat "${AGENTS_DIR}/${agent_file}")"

  # 解析 SubAgent 文件头部的 skills 字段（YAML frontmatter 中的列表）
  local skills=$(sed -n '/^skills:/,/^[^ -]/p' "${AGENTS_DIR}/${agent_file}" | grep '^ *- ' | sed 's/^ *- //')
  for skill in $skills; do
    local skill_file="${SKILLS_DIR}/${skill}/SKILL.md"
    if [ -f "$skill_file" ]; then
      prompt="${prompt}\n\n$(cat "$skill_file")"
    fi
  done
  echo "$prompt"
}
```

### 7.4 Skill 改造方式

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

改造前后对比：

```
改造前: /design Skill → 内部直接定义执行逻辑（方法论+质量标准混在 Skill 中）
改造后: /design Skill → 声明 context: fork + agent → SubAgent 在隔离上下文中执行
                                                        ↓
                                               SubAgent 通过 skills 字段
                                               引用方法论 Skill
```

Skill 文件只保留：
- YAML frontmatter（`name`、`description`、`context: fork`、`agent`）
- 简要说明（用于 Skill 菜单展示和上下文提示）

角色定义、行为准则在 SubAgent 文件中。方法论、质量标准在 Skills 知识层中。

### 7.5 改造后 Skill 文件示例

以 `/design` 为例，改造后的 Skill 文件内容：

```yaml
---
name: design
description: 架构设计。在隔离上下文中启动 pipeline-designer SubAgent 执行架构设计。
context: fork
agent: pipeline-designer
---

# /design

架构设计入口。SubAgent pipeline-designer 将在隔离上下文中执行：
1. 读取 `docs/pipeline/{feature}/handoff_clarify.md`
2. 执行架构设计（方法论由 SubAgent 的 skills 字段引入）
3. 输出到 `docs/pipeline/{feature}/handoff_design.md`

> 如 handoff_clarify.md 不存在，请先执行 /clarify。
```

**原生机制说明**：
- `context: fork`：SubAgent 在独立的上下文窗口中执行，不污染当前会话
- `agent: pipeline-designer`：指定加载 `.claude/agents/pipeline-designer.md`
- SubAgent 文件中的 `skills` 字段会被自动解析，相关 Skills 内容在启动时完整注入
- 无需 Bash 权限或 `claude -p`，Claude Code 原生支持此机制

### 7.6 Skills 知识层设计

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

> 以下 Skills 从各 SubAgent 中提取出来，成为可复用的方法论沉淀。每个 Skill 放在 `~/.claude/skills/pipeline-{name}/SKILL.md`。

#### 7.6.1 `architecture`（架构设计方法论）

**引用者**：pipeline-designer（主用）、pipeline-planner（引用）

**应包含的内容**：
- 先扫描现有代码再设计的方法论（Glob/Grep 了解项目结构、技术栈、代码风格）
- 多方案对比方法论（Tree of Thoughts）：关键决策必须列出 2-3 个备选方案，对比维度包含实现复杂度、与现有代码一致性、可维护性
- 接口定义完整性标准：入参（类型+校验规则）、出参（成功+失败）、错误码、错误场景
- 模块边界设计原则："负责什么"和"不负责什么"
- 设计可追溯性：每个设计决策能对应到需求文档中的具体功能点
- Few-shot 对比示例（好的设计输出 vs 坏的设计输出）

**来源**：从 4.1 节 Designer 的"质量标准"、"多方案对比"、"Few-shot 示例"中提取

#### 7.6.2 `tdd-methodology`（TDD 流程）

**引用者**：pipeline-implementer（主用）、pipeline-fixer（主用）

**应包含的内容**：
- 严格 TDD 执行顺序：写测试 → 运行确认失败（红） → 写实现 → 运行确认通过（绿）→ 重构
- 一任务一 commit 规范：commit message 格式 `feat(Task-N): 描述`，每个 commit 必须包含测试文件
- 阻塞标注规范：无法完成的任务标注 BLOCKED + 原因，不跳过不假装完成
- 测试先行的验证证据要求：Handoff 必须包含测试运行记录（失败 → 通过的完整过程）
- Few-shot 对比示例（好的 TDD 执行记录 vs 坏的执行记录）
- 修复场景的 TDD 变体：每个修复必须附回归测试，修复前后 diff 测试结果

**来源**：从 4.3 节 Implementer 的"质量标准"和 4.6 节 Fixer 的"回归测试"中提取

#### 7.6.3 `code-quality`（代码质量标准）

**引用者**：pipeline-checker（主用）、pipeline-implementer（引用）、pipeline-fixer（引用）

**应包含的内容**：
- 五维检查框架：测试、Lint、类型检查、代码质量规则、AC 覆盖
- 代码质量量化规则：函数长度 <= 40 行、参数 <= 5 个、嵌套 <= 3 层、无空 catch、无裸 except、无硬编码
- 客观证据要求：每项检查必须有命令输出、文件路径:行号、具体数值
- PASS/FAIL 判定标准：五维全 PASS 才是 PASS，不接受模糊结论
- Few-shot 对比示例（好的检查报告 vs 坏的检查报告）

**来源**：从 4.4 节 Checker 的"质量标准"和"Five-dimension check"中提取

#### 7.6.4 `review-standard`（代码审查标准）

**引用者**：pipeline-checker（主用）、pipeline-planner（引用，用于 Design 评审）

**应包含的内容**：
- 对抗性审查思维（Adversarial Mindset）：有罪推定，假设代码有漏洞
- Design 评审标准（DESIGN_OK vs DESIGN_ISSUE）：clarify 规则覆盖、接口完整性、可执行性、过度设计、数据模型
- Plan 评审标准（PLAN_OK vs PLAN_ISSUE）：文件路径验证、AC 可测性、依赖拓扑、任务粒度、设计一致性
- 评审输出格式规范：REVIEW 行 + Issues 列表（具体问题 + 位置 + 修改建议）
- 橡皮图章检测：禁止"看起来没问题"的模糊结论

**来源**：从 4.2 节 Planner 的"评审上游"和 4.4 节 Checker 的"对抗性审查"中提取

#### 7.6.5 `qa-methodology`（QA 验收方法论）

**引用者**：pipeline-qa（主用）

**应包含的内容**：
- 验收标准唯一来源原则：`handoff_clarify.md` 是唯一标准，design/plan 仅用于获取接口信息
- 与 Check 的差异化：Check 验证"代码质量"，QA 验证"功能是否满足需求"
- 逐条需求覆盖方法：需求文档中的每条规则及其正例/反例，逐条 PASS/FAIL + 证据
- 端到端验证方法：启动真实服务 → 健康检查 → 端到端测试 → 停止服务
- 边界条件和排除项必测
- FAIL 项三要素：期望行为 + 实际行为 + 复现命令
- Few-shot 对比示例（好的 QA 报告 vs 坏的 QA 报告）

**来源**：从 4.5 节 QA 的"质量标准"和"Few-shot 示例"中提取

### 7.7 Skills 完整清单（19 个）

#### Pipeline 核心（9 个）

| Skill | 对应 SubAgent | 说明 |
|-------|--------------|------|
| /clarify | 不变（交互式，不适合 SubAgent） | 保持现有，升级输出为 Rules+Examples |
| /design | pipeline-designer | Skill 声明 `context: fork` + `agent`，SubAgent 引用 architecture Skill |
| /plan | pipeline-planner | Skill 声明 `context: fork` + `agent`，SubAgent 引用 architecture + review-standard Skills |
| /run-plan | pipeline-implementer | Skill 声明 `context: fork` + `agent`，SubAgent 引用 tdd-methodology + code-quality Skills |
| /check | pipeline-checker | Skill 声明 `context: fork` + `agent`，SubAgent 引用 code-quality + review-standard Skills |
| /qa | pipeline-qa | Skill 声明 `context: fork` + `agent`，SubAgent 引用 qa-methodology Skill |
| /fix | pipeline-fixer（新增） | Skill 声明 `context: fork` + `agent`，SubAgent 引用 tdd-methodology + code-quality Skills |
| /ship | 不变（需用户确认，不走 SubAgent） | 保持现有 |
| /status | 无 SubAgent（直接读取进度文件） | 新增，读取 `.pipeline-progress-{feature}.json` 展示详情 |

#### 独立工具（6 个，与 Pipeline 无关）

| Skill | 说明 |
|-------|------|
| /refactor | 代码重构，按需使用 |
| /scan | 代码质量巡检，定期使用 |
| /security | 安全漏洞扫描，发布前使用 |
| /perf | 性能分析诊断，按需使用 |
| /worktree | Git Worktree 分支隔离，并行开发 |
| /overview | 接手新项目时理解全貌 |

#### 领域专用（4 个，建议按项目配置）

| Skill | 说明 |
|-------|------|
| /product | 产品设计心理学分析，讨论功能设计时自动融入 |
| /h5 | H5 移动端开发，H5 项目专用 |
| /mcp-builder | MCP 服务器开发，MCP 项目专用 |
| /admin-ui | 后台管理 UI 开发，Admin 项目专用 |

> 领域专用 Skills 建议从全局 `~/.claude/skills/` 移到项目级 `.claude/skills/`，减少非相关项目的上下文占用。

#### 已删除（标记为待清理）

| Skill | 删除原因 |
|-------|---------|
| /gemini-critique | Pipeline Checker+QA 双重门控替代；需求排除项"不追求自己挑战自己替代多视角" |
| /critique | LLM 评审 LLM 输出，质量保障来自 Subagent 角色张力而非加评审层 |
| /test-gen | 被 Implementer 的严格 TDD 流程吸收 |
| /explore | Designer 已包含多方案对比；深度调研在 clarify 阶段沟通 |
| /debug | 合并到 /fix（pipeline-fixer），fix 同时支持手动调试和自动修复 |

---

## 8. 配置

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

### 8.1 SubAgent 完整配置

每个 SubAgent 文件（`.claude/agents/pipeline-*.md`）的 YAML frontmatter 配置：

| SubAgent | allowedTools | skills | model | maxTurns | memory |
|----------|-------------|--------|-------|----------|--------|
| pipeline-designer | Read, Write, Glob, Grep, WebSearch | `[architecture]` | `opus` | 30 | `project` |
| pipeline-planner | Read, Write, Glob, Grep | `[architecture, review-standard]` | `opus` | 30 | `project` |
| pipeline-implementer | Read, Write, Edit, Bash, Glob, Grep | `[tdd-methodology, code-quality]` | `opus` | 50 | `project` |
| pipeline-checker | Read, Bash, Glob, Grep | `[code-quality, review-standard]` | `sonnet` | 20 | - |
| pipeline-qa | Read, Bash, Glob, Grep | `[qa-methodology]` | `sonnet` | 30 | - |
| pipeline-fixer | Read, Write, Edit, Bash, Glob, Grep | `[tdd-methodology, code-quality]` | `opus` | 40 | - |

**配置说明**：

| 字段 | 用途 | 设计理由 |
|------|------|---------|
| `skills` | 声明引用的 Skills（知识层），启动时内容自动注入 | 方法论复用，修改一处全局生效 |
| `model` | 模型选择（opus / sonnet） | Designer/Planner/Implementer/Fixer 需要强推理用 opus；Checker/QA 偏执行验证用 sonnet（成本更低、速度更快） |
| `maxTurns` | 单次会话最大轮次 | 防止 SubAgent 陷入无限循环。Implementer 最高（50）因为需要多轮 TDD；Checker 最低（20）因为五维检查步骤确定 |
| `memory` | 跨会话记忆，`project` 表示按项目维度持久化 | Designer/Planner/Implementer 标记 `project`：跨会话积累项目理解（代码风格、技术偏好、历史设计决策）。Checker/QA/Fixer 不需要跨会话记忆（每次独立判断更客观） |

**SubAgent 文件示例（pipeline-designer.md）**：

```yaml
---
name: pipeline-designer
description: 资深架构师，负责架构设计
skills:
  - architecture
model: opus
maxTurns: 30
memory: project
allowedTools:
  - Read
  - Write
  - Glob
  - Grep
  - WebSearch
---

# 角色身份

你是资深架构师，熟悉本项目代码风格和技术栈。

# 行为准则

- 先扫描现有代码再设计
- 拒绝需求文档未提及的功能
- 关键决策必须多方案对比

# 负向约束

- 不写代码、不做任务拆分（那是 Planner 的事）
- 不引入 clarify 未要求的抽象层或设计模式
- 不修改项目代码文件（Write 仅用于输出 Handoff 文档）

# 输入输出

- 输入：handoff_clarify.md
- 输出：handoff_design.md
- 输出格式：必须包含"输入分析"、"决策"、"产出"三个核心章节

# 质量门控

[引用自 architecture Skill，此处不重复]

# 输出前自检清单

[引用自 architecture Skill，此处不重复]
```

> 注意：角色身份、行为准则、负向约束、输入输出规范保留在 SubAgent 文件中。方法论（如何扫描代码、如何做多方案对比）、质量门控详细标准、Few-shot 示例等方法论性质的内容通过 `skills` 字段从知识层引入。这将 SubAgent 文件控制在 < 3k tokens。

**工具权限原则**：

| 权限级别 | SubAgent | 说明 |
|---------|----------|------|
| 只读 + Write Handoff | Designer, Planner | Write 仅用于输出 Handoff 文档，prompt 中约束不得修改项目代码。事后 diff 校验兜底 |
| 只读 + Bash | Checker, QA | 只读 + 运行测试/Lint 命令，不能修改代码 |
| 全权限 | Implementer, Fixer | 需要改代码、运行测试、commit |

### 8.2 pipeline.sh 配置

在 `pipeline.sh` 脚本顶部定义（bash 变量）：

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| `MAX_FIX` | 10 | QA-Fix 最大修复循环次数 |
| `MAX_REVIEW` | 3（环境变量） | Design-Plan / Plan-Implement 评审最大轮数 |
| `MAX_CHECK_LOOP` | 3（环境变量） | Implement-Check 修复循环最大轮数（QA 前） |
| `STEP_BUDGET` | 10.00（临时占位） | 单步 `claude -p` 的费用上限（USD）。**此为临时值，须通过 3 次实测校准后替换为 P90 x 2** |
| `STEP_TIMEOUT` | 1800 | 单步超时（秒），`run_with_timeout` + `setsid` 进程组隔离硬超时防止 CLI 挂死 |
| `TOTAL_STEPS` | 6 | 主步骤数（design, plan, implement, check, qa, fix），评审轮数不计入总步骤 |
| `TOTAL_BUDGET` | 200.00（临时占位，环境变量） | 总费用安全网（USD）。**此为临时值，须通过 3 次实测校准后替换为 P90 x 1.5**。当前为步数 x STEP_BUDGET 估算，超过时暂停通知用户 |
| `START_STEP` | `design`（环境变量） | 断点续传入口，可选值：`design` / `implement` / `qa`，跳过已完成的阶段 |
| `HUMAN_CHECKPOINT` | `true`（环境变量） | Design/Plan 人工确认开关，默认开启。方向性决策跑偏代价远超代码层面，前 10 个需求建议保持开启。积累信心后可通过 `HUMAN_CHECKPOINT=false` 关闭 |
| `CLI_CMD` | `claude`（环境变量） | CLI 命令，支持 `claude` / `claude-codex` / `claude-gemini` |
| `PROJECT_DIR` | `.`（脚本第二个参数） | 项目根目录，Handoff 文件和进度文件都基于此路径 |
| `SKILLS_DIR` | `$HOME/.claude/skills`（新增） | Skills 知识层目录，pipeline.sh 从此目录读取 Skill 内容拼接到 prompt |

配置直接写在脚本中，不依赖外部配置文件。修改配置只需编辑 `~/.claude/pipeline.sh`。

`CLI_CMD`、`TOTAL_BUDGET`、`HUMAN_CHECKPOINT` 通过环境变量传入，因为它们属于运行时选择而非固定配置。例如：`HUMAN_CHECKPOINT=false TOTAL_BUDGET=200 ~/.claude/pipeline.sh "用户管理" /path/to/project`。

### 8.3 pipeline.sh 中的 Skills 拼接

<!-- UPDATED: 2026-02-21 基于 SubAgent 最佳实践调研优化 -->

> **背景**：`claude -p` CLI 模式下，SubAgent 文件中的 `skills` 字段不会被自动解析。pipeline.sh 需要在构建 prompt 时手动读取 SubAgent 的 `skills` 声明并拼接对应 Skill 内容。

`run_step()` 函数改造：将原来的 `$(cat agent.md)` 替换为 `$(build_prompt agent.md)`，其中 `build_prompt` 自动解析 SubAgent 的 skills 字段并拼接内容。

```bash
# 改造前
$CLI_CMD -p "$(cat "${AGENTS_DIR}/${agent_file}") ${prompt}" ...

# 改造后
$CLI_CMD -p "$(build_prompt "${agent_file}") ${prompt}" ...
```

这确保两种模式（手动 `context: fork` + 自动 `claude -p`）下 SubAgent 获得完全相同的方法论内容。

**模型选择在 CLI 模式下的处理**：`claude -p` 支持 `--model` 参数。pipeline.sh 可从 SubAgent 文件的 `model` 字段中解析模型选择并传入：

```bash
get_model() {
  local agent_file="$1"
  local model=$(grep '^model:' "${AGENTS_DIR}/${agent_file}" | awk '{print $2}')
  echo "${model:-opus}"  # 默认 opus
}

# 在 run_step 中使用
$CLI_CMD -p "$(build_prompt "${agent_file}") ${prompt}" \
  --model "$(get_model "${agent_file}")" \
  --permission-mode "${permission_mode}" \
  --max-budget-usd "${STEP_BUDGET}"
```

> 注意：`maxTurns` 和 `memory` 是 Claude Code 交互式会话的原生机制，在 `claude -p` CLI 模式下不适用。CLI 模式通过 `--max-budget-usd` 和 `STEP_TIMEOUT` 控制执行边界。

### 8.3 Status Line 配置

Claude Code 的 Status Line 功能用于在 UI 状态栏被动显示 Pipeline 进度。需在用户的 Claude Code 设置中配置：

**配置位置**：`~/.claude/settings.json`

```json
{
  "statusLine": {
    "type": "command",
    "command": "f=$(ls -t .pipeline-progress-*.json 2>/dev/null | head -1) && [ -n \"$f\" ] && jq -r '\"[Pipeline: \" + .feature + \" | \" + .current_step + \" \" + (.step_index|tostring) + \"/\" + (.total_steps|tostring) + \" | \" + ((.elapsed_seconds/60)|floor|tostring) + \"m]\"' \"$f\" 2>/dev/null || npx ccstatusline@latest 2>/dev/null || echo ''"
  }
}
```

**显示效果**：`[Pipeline: 用户管理 | implement 3/6 | 12m]`

**前置依赖**：依赖 `jq`（`brew install jq`）。pipeline.sh 启动时会检查 `jq` 是否存在，若不存在会发出警告，此时 Status Line 将无法正常显示。

**工作原理**：
- Status Line 定期执行配置的 shell 命令，将输出显示在 Claude Code UI 状态栏
- 命令查找项目根目录下最近更新的 `.pipeline-progress-{feature}.json`（按 feature 隔离，支持并行）
- 无 Pipeline 运行时（进度文件不存在），回退到 `npx ccstatusline@latest` 显示原有状态信息
- 零 token 开销：Status Line 是 UI 层功能，不消耗 LLM 上下文

---

## 9. 进度可见性与通知机制

用户在 Pipeline 后台运行期间有三层感知渠道，从被动到主动：

| 层级 | 渠道 | 触发方式 | 信息量 | Token 开销 |
|------|------|---------|--------|-----------|
| L1 | Status Line（UI 状态栏） | 被动实时 | 一行摘要 | 零 |
| L2 | `/status` Skill | 用户主动查询 | 详细 JSON | 少量 |
| L3 | 系统通知 | 关键事件推送 | 标题+描述 | 零 |

### 9.1 L1: Status Line（被动实时）

**机制**：Claude Code 的 Status Line 定期执行 shell 命令，读取最近更新的 `.pipeline-progress-{feature}.json` 并在 UI 状态栏显示一行摘要。

**显示效果**：`[Pipeline: 用户管理 | implement 3/6 | 12m]`

**进度文件**：`.pipeline-progress-{feature}.json`（项目根目录下），pipeline.sh 每步写入，按 feature 隔离。格式见 Section 3.3 的 `update_progress()` 函数。

**特点**：
- 用户无需主动操作，打开 Claude Code 就能看到当前步骤
- 零 token 开销，不消耗 LLM 上下文
- 会话独立——pipeline.sh 写文件，Status Line 读文件，两者无耦合
- 无 Pipeline 运行时回退到 `npx ccstatusline@latest`（保留原有状态信息）

### 9.2 L2: /status Skill（主动查询）

用户在任何 Claude Code 会话中说 `/status`，Skill 读取 `.pipeline-progress-{feature}.json` 并格式化展示详细信息（多个 Pipeline 时列出全部）：

```
Pipeline 进度：用户管理
├─ 当前步骤：implement (3/6)
├─ 状态：running
├─ 已用时间：12 分钟
├─ 修复次数：0
├─ CLI Backend：claude-codex
└─ 上次更新：2026-02-13T15:30:00
```

**与 Status Line 的分工**：Status Line 显示一行摘要（被动），`/status` 显示完整详情（主动）。

### 9.3 L3: 系统通知（关键事件推送）

| 场景 | 触发位置 | 通知内容 | 音效 |
|------|---------|---------|------|
| `handoff_clarify.md` 不存在 | 前置检查 | "handoff_clarify.md 不存在" | Basso |
| 残留 Handoff 文件 | 前置检查 | "检测到残留 Handoff 文件，请清理后重试" | Basso |
| 残留 fix 文件 | 前置检查 | "检测到残留 handoff_fix 文件，请清理后重试" | Basso |
| `claude -p` 执行失败 | `run_step` 函数 | "[步骤名] 执行失败" | Basso |
| Handoff 文件未生成 | `run_step` 函数 | "[步骤名] 未生成输出文件" | Basso |
| QA 通过 | QA/Fix 循环 | "{feature} QA 验收通过，请查看结果" | Glass |
| QA 反复失败（≥10 次） | QA/Fix 循环 | "{feature} 修复已达 10 次，请人工排查" | Basso |
| QA 结果解析异常 | QA/Fix 循环（防御性分支） | "QA 结果解析异常（测试框架运行异常），请检查 handoff_qa.md" | Basso |
| 同一 feature 重复启动 | 前置检查 | "{feature} 已有 Pipeline 在运行" | Basso |
| Design 评审通过 | Design-Plan 循环 | "{feature} Design 评审通过，进入 Plan" | Glass |
| Design 评审循环耗尽 | Design-Plan 循环 | "{feature} Design 经 3 轮评审仍有问题" | Basso |
| Plan 评审通过 | Plan-Implement 循环 | "{feature} Plan 评审通过，进入 Implement" | Glass |
| Plan 评审循环耗尽 | Plan-Implement 循环 | "{feature} Plan 经 3 轮评审仍有问题" | Basso |
| Check 通过（进入 QA） | Implement-Check 循环 | 无通知（直接进入 QA） | — |
| Check 循环耗尽 | Implement-Check 循环 | "{feature} 代码检查 3 轮未通过" | Basso |
| Design 评审输出格式异常 | Design-Plan 循环 | "Design 评审输出缺少 REVIEW 行" | Basso |
| Plan 评审输出格式异常 | Plan-Implement 循环 | "Plan 评审输出缺少 REVIEW 行" | Basso |
| Check 结果解析异常 | Implement-Check 循环（防御性分支） | "Check 结果解析异常（测试框架运行异常），请检查 handoff_check.md" | Basso |

通知通过 pipeline.sh 内的 `notify` / `notify_error` 函数实现（见 Section 3.3），支持 macOS + Linux 跨平台，始终输出到日志：

```bash
notify() {
  if command -v osascript &>/dev/null; then
    osascript -e "display notification \"$2\" with title \"$1\" sound name \"Glass\"" 2>/dev/null || true
  elif command -v notify-send &>/dev/null; then
    notify-send "$1" "$2" 2>/dev/null || true
  fi
  echo "[NOTIFY] $1: $2"  # 始终输出到日志
}
```

通知失败不影响 Pipeline 执行。日志始终可查。

### 9.4 方案选型说明

| 方案 | 结论 | 原因 |
|------|------|------|
| Agent Teams | 不采用 | 设计用于并行协作，串行 pipeline 是大炮打蚊子；无 session resumption（会话关闭 = teammate 死亡） |
| Bash `run_in_background` | 不采用 | 3 个已知严重 Bug（Issue #11716 token 爆炸 11.6x、#16958 上下文膨胀、#19097 孤儿进程），部分 closed as NOT_PLANNED |
| Progress File + Status Line | **采用** | 被动实时、零 token、会话独立、官方支持、无已知 Bug |

---

## 10. 交付物清单

| 交付物 | 路径 | 说明 |
|--------|------|------|
| Shell 脚本编排器 | `~/.claude/pipeline.sh` | 确定性流程控制（bash），支持 `CLI_CMD` 和 `PROJECT_DIR` |
| Designer Subagent | `~/.claude/agents/pipeline-designer.md` | 架构设计质量定义 |
| Planner Subagent | `~/.claude/agents/pipeline-planner.md` | 开发计划质量定义 |
| Implementer Subagent | `~/.claude/agents/pipeline-implementer.md` | 执行开发质量定义 |
| Checker Subagent | `~/.claude/agents/pipeline-checker.md` | 代码检查质量定义 |
| QA Subagent | `~/.claude/agents/pipeline-qa.md` | 验收测试质量定义 |
| Fixer Subagent | `~/.claude/agents/pipeline-fixer.md` | 修复质量定义 |
| /status Skill | `~/.claude/skills/pipeline-status/SKILL.md` | 读取 `.pipeline-progress-{feature}.json` 展示详细进度 |
| Status Line 配置 | `~/.claude/settings.json` 中 `statusLine` 字段 | 被动实时显示 Pipeline 进度摘要 |
| /clarify 升级 | 更新现有 Skill | 增加挑战能力 + 输出 Handoff 格式 + 后台启动 pipeline.sh |
| 现有 Skill 改造 | 更新 /design /plan /run-plan /check /qa | 改为调用对应 Subagent（手动模式入口） |
| /fix Skill 新增 | 新建 Skill | 调用 pipeline-fixer |

### 10.1 Subagent Prompt 验收标准（前置门控）

> 6 个 Subagent prompt 文件是方案天花板。没有高质量的 prompt，流程编排毫无意义。

**交付标准**：每个 `pipeline-*.md` 文件必须包含以下 5 个段落（缺一不可）：

| 段落 | 内容要求 | 验收方式 |
|------|---------|---------|
| 角色身份定义 | 身份 + 行为准则 + 负向约束（三要素） | 人工 review |
| Few-shot 对比示例 | ≥ 1 组"好输出 vs 坏输出"对比 | 人工 review |
| 自检清单 | ≥ 5 条检查项，覆盖本节 4.x 定义的质量门控 | 逐条核对 |
| 输出格式模板 | Handoff 文档结构（输入分析/决策/产出/交接项） | 格式校验 |
| 负向约束 | ≥ 3 条 "Do NOT" 约束 | 人工 review |

**验收流程**：
1. **骨架 review（用户 30 分钟）**：用户检查角色定义、负向约束、Few-shot 的"坏输出"是否触及真实问题
2. **A/B 实测**：拿一个已手动完成的需求用 Pipeline 重跑，对比产出差异
3. **持续迭代**：每次 Pipeline 失败回溯到对应 prompt 并记录"这个 prompt 没拦住什么"，积累 5 条后修订

### 10.2 前置验证清单（Go-Live 准入）

以下全部满足才可正式使用 Pipeline：

- [ ] `claude -p --permission-mode plan` 实测通过，有日志证据（Designer/Planner 步骤依赖此模式）
- [ ] 3 次不同规模需求的实测费用数据已记录，STEP_BUDGET/TOTAL_BUDGET 已据此调整
- [ ] 6 个 Subagent prompt 文件已交付且通过骨架 review
- [ ] `preflight_check()` 覆盖 `jq`/`gtimeout`/`setsid` 三个外部依赖
- [ ] 1 次冒烟测试全流程通过
- [ ] shellcheck 对 pipeline.sh 零 warning

---

## 11. 验证方案

用一个真实的小需求跑通整个流程：

### 11.1 自动模式验证

1. 用户执行 `/clarify`，输出 `docs/pipeline/{feature}/handoff_clarify.md`
2. 用户说"开始"，Claude 后台启动 `pipeline.sh "{feature}"`
3. 验证每步：
   - `claude -p` 是否正常启动和退出（退出码 0）
   - Handoff 文档是否生成在正确的 `{feature}` 命名空间下
   - QA 结果是否通过 pipeline.sh 独立运行测试套件正确判定 PASS/FAIL
   - 锁目录（`mkdir` 原子操作）是否正常创建和清理
4. 故意制造一个缺陷，验证 QA/Fix 循环能否收敛
5. QA 通过后收到系统通知

### 11.2 手动模式验证

1. 单独执行 `/check`，确认通过 Task 工具调用了 `pipeline-checker` Subagent
2. 验证 Skill 和 pipeline.sh 调用同一份 Subagent 文件

### 11.3 并行验证

1. 同时启动两个不同 feature 的 Pipeline
2. 验证 Handoff 文件互不干扰
3. 验证同一 feature 重复启动被锁文件阻止

### 11.4 进度可见性验证

1. Pipeline 运行中，打开 Claude Code，Status Line 显示 `[Pipeline: {feature} | {step} N/6 | Xm]`
2. Pipeline 运行中，执行 `/status`，显示完整进度详情（feature、步骤、状态、耗时、backend 等）
3. Pipeline 未运行时，Status Line 回退显示 `ccstatusline` 原有状态，`/status` 提示无活跃 Pipeline
4. 使用 `CLI_CMD=claude-codex` 启动 Pipeline，`/status` 显示的 CLI Backend 为 `claude-codex`
5. Pipeline 完成后，`.pipeline-progress-{feature}.json` 状态为 `completed`，Status Line 显示最终状态

### 11.5 前置评审循环验证

1. Design 输出含故意遗漏（如缺少一个接口定义），验证 Planner 评审能否发现 DESIGN_ISSUE 并触发修正循环
2. Plan 输出含不可执行的 AC（如"界面友好"），验证 Implementer 评审能否发现 PLAN_ISSUE
3. Implement 输出含 lint 错误，验证 Check FAIL 后 Fix → re-Check 循环能否收敛
4. 3 轮评审仍不通过时，验证 pipeline.sh 正确退出并发送 Basso 通知
5. Design 评审输出缺少 REVIEW 行时，验证 pipeline.sh 正确退出（不重试）
6. Check 和 QA 均通过 pipeline.sh 独立运行测试套件判定 PASS/FAIL，验证 `parse_result()` 共用逻辑正确解析退出码（0 → PASS；非 0 → FAIL）

### 11.6 新增功能验证

1. **START_STEP 断点续传**：`START_STEP=implement` 跳过 Design-Plan 阶段直接进入 Implement，验证前置产物检查（clarify+design+plan 存在、run 不存在）
2. **权限模式分级**：Designer/Planner 步骤使用 `--permission-mode plan`，其余角色（Implementer/Fixer/Checker/QA）使用 `--permission-mode bypassPermissions`
3. **事后 diff 校验**：在只读角色（如 Designer）的 Subagent 中故意修改项目代码文件，验证 `verify_no_code_changes` 检测到并 `exit 1`
4. **估算费用累计**：验证 `TOTAL_COST` 按步骤计数 × `STEP_BUDGET` 估算累加，超过 `TOTAL_BUDGET` 时暂停
5. **Implement 回滚锚点**：验证 `IMPL_BASE` 记录了正确的 git HEAD hash
6. **per-feature 日志文件**：验证 `docs/pipeline/{feature}/pipeline.log` 包含完整执行日志
7. **review 按轮次编号**：2 轮 Design 评审产生 `review_design_1.md` 和 `review_design_2.md`
8. **进程组超时清理**：模拟 CLI 挂死场景，验证 `run_with_timeout` + `setsid` 整个进程组被 KILL
9. **`--permission-mode plan` 非交互兼容性**：验证 `claude -p --permission-mode plan` 在非交互模式下正常执行（plan 模式通常需要用户审批，需确认 `-p` 下的行为）
10. **INFRA_ERROR 路径**：模拟 QA 阶段服务启动失败（如端口占用），验证 pipeline.sh 不进入 Fix 循环而是直接 exit 1 + 通知用户
11. **preflight_check**：在未安装 jq 的环境中运行 pipeline.sh，验证 preflight_check() 阻断启动并给出安装指引
12. **费用实测校准**：完成 3 次不同规模需求实测后，STEP_BUDGET 和 TOTAL_BUDGET 已替换为基于实际数据的值

### 11.7 验证标准

- 自动模式：全流程不需要用户在中间环节干预（异常除外）
- 手动模式与自动模式的执行质量一致（使用同一份 Subagent）
- pipeline.sh 的流程控制（步骤顺序、循环计数、PASS/FAIL 判断）100% 确定性，不依赖 LLM
- 进度可见性：用户在任何时刻都能通过 Status Line 或 `/status` 了解 Pipeline 当前状态
- CLI 兼容性：`CLI_CMD=claude-codex` 和 `CLI_CMD=claude-gemini` 与默认 `claude` 行为一致
