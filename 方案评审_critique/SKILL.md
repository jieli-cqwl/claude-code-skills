---
name: critique
command: critique
user_invocable: true
parallel_mode: true
description: 方案评审。在 /clarify、/explore、/design、/plan 完成后使用，以批评者视角审查方案，找出遗漏、矛盾、风险。特别适合非技术用户无法自行评估方案质量的场景。
---

# 方案评审 (Critique)

> **角色**：对抗式评审员（Agent-as-a-Judge）
> **目标**：以批评者视角审查方案，找出问题和风险
> **原则**：挑刺优先、业务语言、可操作建议
> **铁律**：**发现即修复，不分级** — 所有问题都必须修复，不留技术债
> **理论基础**：[CRITIC 框架](https://openreview.net/forum?id=Sx038qxjek)、[Agent-as-a-Judge](https://arxiv.org/html/2508.02994v1)
> **思考模式**：启用 ultrathink 深度思考，确保全面分析风险和遗漏

---

## 触发条件

当用户使用以下任一方式时，立即激活此 skill：
- 说"**评审方案**"或"**方案评审**"（主触发词）
- 使用命令：`/critique`
- 说"挑挑毛病"、"有没有问题"
- 说"方案靠谱吗"、"审查一下"
- 说"找找漏洞"

**适用场景**：
- /clarify、/explore、/design、/plan 完成后
- 实现前想确认方案质量
- 非技术用户无法自行评估方案

---

## 核心理念

**"LLM 批评能力比生成能力更强"** — 让一个 Agent 评审另一个 Agent 的输出是有效的。

**解决的问题**：
- 非技术用户无法判断方案质量
- AI 自己出的方案自己不会质疑
- 问题在实现后才发现，修复成本高

---

## 与 /check 的区别

| 维度 | `/critique`（本 Skill） | `/check` |
|------|----------------------|----------|
| **检查对象** | 还没实现的**方案** | 已写完的**代码** |
| **时机** | 设计阶段，实现前 | 开发完成后 |
| **目的** | 方案设计得好不好 | 代码写得对不对 |
| **发现问题** | 需求遗漏、设计缺陷 | 代码 bug、规范违反 |
| **修复成本** | 低（还没开始写） | 高（代码已写完） |

---

## 依赖规范

> **执行前按需读取**：以下规范文件在评审时按需加载。

| 规范文件 | 覆盖评审项 |
|---------|-----------|
| `~/.claude/rules/RULES.md` | 项目铁律、禁用词汇、文档生命周期 |
| `~/.claude/reference/全栈开发.md` | 前后端同步、API 设计规范 |
| `~/.claude/reference/性能效率.md` | 缓存策略、批量操作、N+1 问题 |
| `~/.claude/reference/代码质量.md` | 函数设计、错误处理、类型注解 |

**执行 /critique 时，根据评审对象自动读取相关规范文件。**

---

## 评审维度（10 维度）

| 维度 | 检查内容 | 业务语言示例 |
|------|---------|-------------|
| **完整性** | 是否有遗漏场景、边界情况 | "没考虑用户取消操作的情况" |
| **一致性** | 前后是否矛盾、与规范是否冲突 | "前面说支持批量，后面只处理单个" |
| **可行性** | 技术上能否实现、依赖是否可用 | "全房通接口不支持这个参数" |
| **风险** | 可能出什么问题、有什么隐患 | "并发时可能发重复消息给用户" |
| **遗漏分析** | 缺少了什么必要的功能或处理 | "没有定义失败后的重试策略" |
| **技术债务** | 是否引入难以维护的设计 | "这个方案后期改起来很麻烦" |
| **安全性** | 是否有安全漏洞或隐患 | "用户输入没有校验，可能被注入" |
| **性能影响** | 是否会导致性能问题 | "每次操作都要查询全表，数据多了会很慢" |
| **可维护性** | 代码是否易于理解和修改 | "这个设计太复杂，后面的人看不懂" |
| **用户体验** | 对用户使用的影响 | "操作步骤太多，用户会觉得繁琐" |

---

## 执行流程

### Phase 1: 识别评审对象

```markdown
## 评审对象识别

**最近完成的环节**：[/clarify | /explore | /design | /plan]
**输出内容**：[文档名称或内容摘要]
**涉及文件**：[如有，列出相关文件]
```

如果无法识别，询问用户要评审什么。

---

### Phase 2: 读取相关规范

根据评审对象，读取对应的规范文件：

| 评审对象 | 必读规范 |
|---------|---------|
| /clarify 输出 | `~/.claude/rules/RULES.md`（项目铁律） |
| /explore 输出 | `~/.claude/reference/性能效率.md`（性能约束） |
| /design 输出 | `~/.claude/reference/全栈开发.md`、`~/.claude/reference/性能效率.md` |
| /plan 输出 | `~/.claude/reference/全栈开发.md`、`~/.claude/reference/代码质量.md` |

---

### Phase 3: 并行评审（10 Agent）

> **并行架构**：启动 10 个独立 Agent 同时执行评审，大幅提升评审效率。

**执行方式**：使用 Task 工具同时启动 10 个 subagent（subagent_type=general-purpose）

#### 10 Agent 并行任务分配

| Agent | 评审维度 | 职责描述 |
|-------|---------|---------|
| Agent 1 | 完整性检查 | 检查正常/异常流程、边界情况、用户角色覆盖 |
| Agent 2 | 一致性检查 | 检查方案内部一致性、与规范一致性、与现有系统一致性 |
| Agent 3 | 可行性评估 | 评估技术可实现性、依赖可用性、时间资源充足性 |
| Agent 4 | 风险识别 | 识别并发/竞态、数据一致性、第三方依赖、安全风险 |
| Agent 5 | 遗漏分析 | 分析缺少的必要功能、处理流程、配置项 |
| Agent 6 | 技术债务评估 | 评估设计复杂度、维护成本、扩展难度 |
| Agent 7 | 安全性审查 | 审查输入校验、权限控制、敏感数据处理 |
| Agent 8 | 性能影响分析 | 分析查询效率、资源消耗、并发承载能力 |
| Agent 9 | 可维护性评估 | 评估代码可读性、模块耦合度、文档完整性 |
| Agent 10 | 用户体验影响 | 评估操作流程、响应速度、错误提示友好度 |

#### 每个 Agent 的执行模板

```markdown
## [Agent N] - [评审维度]

**检查项**：
- [ ] 检查项 1
- [ ] 检查项 2
- [ ] 检查项 3

**发现的问题**：
1. [具体问题，用业务语言描述]
2. ...

**评分**：高 / 中 / 低
```

#### Agent 输出格式（结构化 JSON）

每个 Agent 必须返回以下结构化输出：

```json
{
  "agent_id": "agent_N",
  "agent_name": "评审维度名称",
  "status": "success | failed | timeout",
  "output": {
    "issues": [
      {
        "description": "问题描述（业务语言）",
        "impact": "业务影响",
        "suggestion": "修复建议"
      }
    ],
    "score": "高 | 中 | 低",
    "highlights": ["做得好的地方"]
  }
}
```

#### 错误处理规范

| 错误类型 | 处理方式 |
|---------|---------|
| Agent 超时 | 记录超时，继续等待其他 Agent，最终报告中标注 |
| Agent 失败 | 记录失败原因，该维度标记为"未完成评审" |
| 部分 Agent 失败 | 基于成功 Agent 的结果输出报告，明确标注未完成维度 |
| 全部 Agent 失败 | 报告错误，建议用户重试或手动评审 |

**等待所有 Agent 完成后继续 Phase 4。**

---

### Phase 4: 汇总输出（串行）

> 主 Agent 综合所有评审意见，生成评审报告。

```markdown
## 评审报告

**评审对象**：[/design 输出的架构设计]
**评审时间**：YYYY-MM-DD HH:mm

---

### 总体评价（10 维度）

| 维度 | 评分 | 说明 |
|------|------|------|
| 完整性 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 一致性 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 可行性 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 风险 | ✅ 低 / ⚠️ 中 / ❌ 高 | [一句话说明] |
| 遗漏 | ✅ 低 / ⚠️ 中 / ❌ 高 | [一句话说明] |
| 技术债务 | ✅ 低 / ⚠️ 中 / ❌ 高 | [一句话说明] |
| 安全性 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 性能 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 可维护性 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |
| 用户体验 | ✅ 高 / ⚠️ 中 / ❌ 低 | [一句话说明] |

**总体建议**：✅ 可以继续 / ❌ 必须修复后继续

---

### 🔴 必须修复

> **原则：发现即修复，不留技术债**
>
> 所有评审发现的问题都必须修复。大问题是小问题累积出来的，要做就做到最好。

| # | 问题 | 业务影响 | 修复建议 |
|---|------|---------|---------|
| 1 | [问题描述，用业务语言] | [会导致什么后果] | [具体修复方法] |
| 2 | ... | ... | ... |

---

### 🟢 做得好的地方

> 肯定方案中的优点，建立信心

1. [优点 1]
2. [优点 2]

---

### 下一步

- [ ] 修复全部 X 个问题
- 修复后重新 /critique 确认
- 全部通过后继续执行 [/plan | /run-plan | ...]

或

- ✅ 无问题，可以继续执行 [下一个环节]
```

---

## 业务语言翻译表

**技术问题 → 业务语言**：

| 技术描述 | 业务语言 |
|---------|---------|
| 缺少异常处理，可能导致未捕获的 RuntimeError | 系统出错时会卡住，用户看不到任何提示 |
| N+1 查询问题 | 数据多的时候页面要等很久才能加载出来 |
| 缺少事务控制 | 批量操作可能只成功一半，数据会乱 |
| 没有并发控制 | 多人同时操作时可能互相覆盖，数据丢失 |
| 缺少重试机制 | 网络不好时操作会直接失败，用户要重新来 |
| 硬编码配置 | 换环境要改代码，容易出错 |
| 没有缓存 | 每次操作都很慢，用户体验差 |
| 接口没有限流 | 被恶意调用时系统会崩溃 |

---

## 不同环节的评审重点

### 评审 /clarify 输出（需求文档）

**重点**：
- 需求是否完整、有无歧义
- 边界情况是否定义清楚
- 验收标准是否可测量

**常见问题**：
- "用户可以管理文档" → 什么操作算管理？增删改查都支持吗？
- "系统要快" → 多快算快？1 秒还是 5 秒？

---

### 评审 /explore 输出（方案选型）

**重点**：
- 方案对比是否全面
- 选择依据是否充分
- 有无遗漏的主流方案

**常见问题**：
- 只对比了 2 个方案，漏了更适合的
- 选择依据是"简单"，但没考虑可扩展性

---

### 评审 /design 输出（架构设计）

**重点**：
- 模块职责是否清晰
- 接口设计是否完整（含错误处理）
- 数据模型是否合理
- 是否违反项目规范

**常见问题**：
- 没有定义接口的错误响应
- 缺少异常情况的处理流程
- 模块间有循环依赖

---

### 评审 /plan 输出（实施计划）

**重点**：
- 步骤顺序是否合理（先后端后前端）
- 每步是否可验证
- 是否遗漏关键步骤
- 是否违反项目铁律
- **AC 是否引用而非重新定义**（新增）
- **测试设计状态是否完整**（新增）

**AC 引用检查项**（阻塞项）：

| 检查项 | 要求 | 常见问题 |
|--------|------|---------|
| AC 来源声明 | 必须声明引用 /clarify 的 AC | 直接定义新的验收场景 |
| AC 文档路径 | 必须指向 `docs/需求文档/clarify_*.md` | 路径错误或缺失 |
| 禁止重新定义 | 不能修改或新增 AC | 在 /plan 中新增了 /clarify 没有的场景 |
| 测试设计状态 | 必须有测试设计检查点 | 缺少门控检查 |

**验收测试场景检查项**（阻塞项）：

| 检查项 | 要求 | 常见问题 |
|--------|------|---------|
| 引用而非定义 | 引用 /clarify 的 AC 表格 | 重新定义 AC |
| 格式正确 | 引用链接 + AC 列表 | 只写了描述，没有引用 |
| 完整性 | 引用所有相关 AC | 遗漏部分 AC |

**常见问题**：
- 先做前端后做后端
- 缺少联调验证步骤
- 步骤粒度太粗，无法验证
- **AC 重新定义而非引用**（阻塞）- /plan 中的 AC 与 /clarify 不一致
- **缺少测试设计状态检查点**（阻塞）- 没有门控确保测试先于开发
- **AC 来源文档路径错误**（阻塞）- 无法追溯到单一来源

---

## 与其他 Skills 的关系

```
/clarify（需求澄清）
    ↓
/explore（方案探索）
    ↓
/design（架构设计）
    ↓ 完成后自动触发
/critique（评审架构）← 自动
    ↓ 评审通过后
/plan（写计划）
    ↓ 完成后自动触发
/critique（评审计划）← 自动
    ↓ 评审通过后
/run-plan（执行计划）
    ↓
/check（检查代码）
    ↓
/qa（测试验收）
```

---

## 禁止行为

| 禁止 | 原因 |
|------|------|
| 敷衍评审，全说"没问题" | 失去评审意义 |
| 用技术术语吓唬用户 | 用户看不懂，无法判断 |
| 只挑刺不给解决方案 | 用户不知道怎么改 |
| 评审时开始改方案 | 评审和修改是两个环节 |

---

## 完成检查清单

- [ ] 识别了评审对象
- [ ] 读取了相关规范
- [ ] 启动了 10 个 Agent 并行评审
- [ ] 所有 Agent 返回结果（或已处理超时/失败）
- [ ] 问题用业务语言描述
- [ ] 每个问题都有修复建议
- [ ] 所有问题都列为必须修复（不分级）
- [ ] 给出了明确的下一步建议

---

## ✅ 完成提示

```
✅ 方案评审完成

📊 评审结果：
- 评审阶段：[/clarify | /explore | /design | /plan]
- 发现问题：X 个（全部必须修复）
- 总体评价：[可以继续 / 必须修复后继续]

🎯 下一步：
- [修复全部问题，然后重新 /critique]

评审通过后继续（根据当前阶段）：
- 评审 /clarify 输出 → /explore（方案探索）
- 评审 /explore 输出 → /design（架构设计）
- 评审 /design 输出 → /plan（写计划）
- 评审 /plan 输出 → /test-gen（测试先行）→ /run-plan
```

---

**版本**：v1.4（并行评审版）
**创建日期**：2025-01-27
**更新日期**：2026-01-29
**理论基础**：CRITIC 框架、Agent-as-a-Judge、Self-Critique
**v1.4 变更**：
- 实现 10 Agent 并行评审架构
- 评审维度从 5 个扩展到 10 个（新增：遗漏分析、技术债务、安全性、性能、可维护性、用户体验）
- Phase 3 改为并行执行，Phase 4 为串行汇总
- 添加结构化 JSON 输出格式
- 添加错误处理规范（超时、失败、部分失败）
**v1.3 变更**：
- 完成提示增加「评审阶段」字段，明确当前评审的是哪个环节
- 下一步建议根据评审阶段动态输出，避免跳过 /test-gen 等环节
- 修复：评审 /plan 后直接跳到 /run-plan 的问题
**v1.2 变更**：
- 取消问题分级，所有问题都必须修复
- 原则：发现即修复，不留技术债
- 大问题是小问题累积出来的，要做就做到最好
